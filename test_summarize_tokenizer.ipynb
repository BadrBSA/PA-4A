{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import time\n",
    "\n",
    "start_all = time.time()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    use_rslora=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "        # load_in_8bit=True,\n",
    "        # load_in_4bit=True,\n",
    "        llm_int8_enable_fp32_cpu_offload=True,\n",
    "        # llm_int8_has_fp16_weight=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=\"float16\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "226f31a28853452998dece174567b467"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", quantization_config=quantization_config, device_map=\"auto\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#from datasets import load_dataset\n",
    "#dataset = load_dataset(\"pszemraj/booksum-short\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#text = dataset['train']['chapter'][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "with open(\"data/books/J._K._Rowling_-_Harry_Potter_1_-_Sorcerers_Stone.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127505\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.encode(text, return_tensors='pt')[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fonctions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def enlever_inst(contenu):\n",
    "    # Trouver la position de la balise [/INST]\n",
    "    fin_inst = contenu.find('[/INST]')\n",
    "\n",
    "    # Vérifier si la balise [/INST] a été trouvée\n",
    "    if fin_inst != -1:\n",
    "        # Supprimer tout le texte avant et y compris la balise [/INST]\n",
    "        resultat = contenu[fin_inst + len('[/INST]'):]\n",
    "        return resultat\n",
    "    else:\n",
    "        # Si la balise [/INST] n'a pas été trouvée, retourner le contenu original\n",
    "        return contenu\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Diviser le texte en segments de 500 caractères ou moins\n",
    "# mettre 8000\n",
    "def split_text_into_token_segments(text, token_amount=5000):\n",
    "    segments = []\n",
    "\n",
    "    encoded_text = tokenizer.encode(text=text, return_tensors='pt')\n",
    "\n",
    "    sequence=[]\n",
    "    for tensor in encoded_text[0]:\n",
    "        sequence.append(tensor)\n",
    "\n",
    "        if len(sequence) == token_amount:\n",
    "            segments.append(sequence)\n",
    "            sequence = []\n",
    "\n",
    "    if sequence :\n",
    "        segments.append(sequence)\n",
    "\n",
    "    return segments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def summarize_token_segment(segments, instructions = 'make me a summary of the following text: '):\n",
    "\n",
    "    summaries = []\n",
    "    counter = 0\n",
    "    for segment in segments:\n",
    "        print(counter)\n",
    "        counter += 1\n",
    "        text_to_summarize = tokenizer.decode(segment, skip_special_tokens=True)\n",
    "        message = [\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": f\"{instructions}\"\n",
    "                           f\"{text_to_summarize}\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        encodeds = tokenizer.apply_chat_template(message, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        generated_ids = model.generate(encodeds, do_sample=True, max_new_tokens=1000, pad_token_id=tokenizer.pad_token_id)\n",
    "        decoded = tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "        summaries.append([enlever_inst(decoded[0])])\n",
    "\n",
    "    return summaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def group_summaries(summaries):\n",
    "    grouped_summaries = ''.join([item for sublist in summaries for item in sublist])\n",
    "    return split_text_into_token_segments(grouped_summaries)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def full_process(text):\n",
    "    token_segments = split_text_into_token_segments(text)\n",
    "    while True:\n",
    "        print('a')\n",
    "        summary = summarize_token_segment(token_segments)\n",
    "        print('b')\n",
    "        grouped_summaries = group_summaries(summary)\n",
    "        print('c')\n",
    "        if len(grouped_summaries) == 1:\n",
    "            return summarize_token_segment(grouped_summaries)\n",
    "        else:\n",
    "            token_segments = grouped_summaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\Desktop\\ESGI\\master\\M1\\S2\\PA-4A\\venv\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:688: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n",
      "c\n",
      "a\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n",
      "c\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "test = full_process(text)\n",
    "end = time.time()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time of execution of above program is : 1611119.2829608917 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"The time of execution of above program is :\",\n",
    "      (end-start) * 10**3, \"ms\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time of execution of the entire program is : 1710936.838388443 ms\n"
     ]
    }
   ],
   "source": [
    "end_all = time.time()\n",
    "\n",
    "print(\"The time of execution of the entire program is :\",\n",
    "      (end_all-start_all) * 10**3, \"ms\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[[' In the opening chapter of \"Harry Potter and the Sorcerer\\'s Stone,\" Harry Potter, a muggle child living with his muggle relatives, the Dursleys, experiences strange occurrences and dreams of being a wizard. Mr. Dursley dismisses these events as tricks of the mind. Meanwhile, Albus Dumbledore and Professor McGonagall discuss Voldemort\\'s return and the rumors about the Potter family. Hagrid, the Keeper of Keys and Grounds at Hogwarts, arrives to take Harry to the magical school, revealing his true identity as a wizard.\\n\\nHarry, Hagrid, and Dumbledore go to Diagon Alley to buy school supplies, and Harry purchases a wand, which chooses him. They meet Hermione Granger and set off for Hogwarts on the Hogwarts Express. Harry is excited to start his new life at Hogwarts but is met with challenges as they suspect Professor Snape of attempting to steal the Sorcerer\\'s Stone, Harry\\'s first Quidditch match approaches, and the Christmas holidays arrive.\\n\\nWhile searching for information on the Sorcerer\\'s Stone and Nicolas Flamel, Harry and his friends, Ron Weasley and Hermione Granger, encounter Snape jinxing Harry\\'s broom during a Quidditch match, Harry\\'s birthday presents include an invisibility cloak from an unknown sender, and they overhear Malfoy insulting their family, resulting in a fight. Harry also discovers Dumbledore\\'s mirror, the Mirror of Erised, and becomes enamored with it but is warned of its dangers. They continue to search for the wounded unicorn, with Harry, Ron, and Malfoy going separate ways to find it and eventually healing it.\\n\\nThroughout the text, Harry, Ron, and Hermione face various challenges as they uncover the truth about the Sorcerer\\'s Stone and Snape\\'s involvement. They struggle with fear, frustration, and isolation as they piece together the puzzle of the mystery. Despite the obstacles, they remain determined and are supported by their friendship and guidance from Dumbledore.\\n\\nKey events and themes:\\n\\n* Harry\\'s identity as a wizard is revealed.\\n* Suspected theft of the Sorcerer\\'s Stone by Professor Snape.\\n* Strained relationships with the Dursleys.\\n* Harry\\'s excitement for Quidditch and Christmas.\\n\\nKey characters:\\n\\n* Harry Potter\\n* Mr. Dursley\\n* Mrs. Dursley\\n* Petunia Dursley\\n* Percy Dursley\\n* Albus Dumbledore\\n* Professor McGonagall\\n* Hagrid\\n* Ron Weasley\\n* Hermione Granger\\n* Professor Snape\\n* Nicolas Flamel\\n* Malfoy.\\n\\nKey words and phrases:\\n\\n* Muggle\\n* Magic\\n* Wands\\n* Wizarding World\\n* Hogwarts\\n* Transfiguration\\n* Quidditch\\n* Sorting Hat\\n* Platform 9 and 3/4\\n* Hogwarts Express\\n* Diagon Alley\\n* Ollivanders Wand Shop\\n* Unicorn.</s>']]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "message = [\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": f\"make me a short summary of the following text without being to precise :\"\n",
    "                           f\"{test}\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "encodeds = tokenizer.apply_chat_template(message, return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(encodeds, do_sample=True, max_new_tokens=1000, pad_token_id=tokenizer.pad_token_id)\n",
    "decoded = tokenizer.batch_decode(generated_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "' In the first chapter of \"Harry Potter and the Sorcerer\\'s Stone,\" Harry, a muggle boy living with muggle relatives, experiences strange occurrences and dreams of being a wizard. He is later taken to Hogwarts, a magical school, by Hagrid, where he meets Ron and Hermione and starts his new life. They encounter various challenges, including suspicious behavior from Professor Snape and the sorcerer\\'s stone being stolen. Harry discovers his invisibility cloak and faces off against Malfoy. The group continues to uncover the truth about the sorcerer\\'s stone whilst dealing with fear, isolation, and the dangers of the Mirror of Erised. Along the way, they meet several key characters and come across various magical elements such as wands, Quidditch, and the Hogwarts Express. Key events include the revelation of Harry\\'s wizarding identity, the suspicion surrounding Snape, and their excitement for Quidditch and Christmas.</s>'"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enlever_inst(decoded[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
