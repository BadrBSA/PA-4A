{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-29T21:43:46.689621Z",
     "start_time": "2024-04-29T21:43:43.708295Z"
    }
   },
   "source": [
    "from transformers import pipeline\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T21:59:43.302901Z",
     "start_time": "2024-04-29T21:59:41.703826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipe = pipeline('summarization', model='bart_model')\n",
    "gen_kwargs = {'length_penalty': 0.8, 'num_beams': 8, \"max_length\": 200}\n",
    "\n",
    "custom_dialogue=\"\"\"\n",
    "In my younger and more vulnerable years my father gave me some advice that I've been turning over in my mind ever since.\n",
    "\n",
    "'Whenever you feel like criticizing any one,' he told me, 'just remember that all the people in this world haven't had the advantages that you've had.'\n",
    "\n",
    "He didn't say any more but we've always been unusually communicative in a reserved way, and I understood that he meant a great deal more than that. In consequence, I'm inclined to reserve all judgments, a habit that has opened up many curious natures to me and also made me the victim of not a few veteran bores. The abnormal mind is quick to detect and attach itself to this quality when it appears in a normal person, and so it came about that in college I was unjustly accused of being a politician, because I was privy to the secret griefs of wild, unknown men. Most of the confidences were unsought -- frequently I have feigned sleep, preoccupation, or a hostile levity when I realized by some unmistakable sign that an intimate revelation was quivering on the horizon; for the intimate revelations of young men, or at least the terms in which they express them, are usually plagiaristic and marred by obvious suppressions. Reserving judgments is a matter of infinite hope. I am still a little afraid of missing something if I forget that, as my father snobbishly suggested, and I snobbishly repeat a sense of the fundamental decencies is parcelled out unequally at birth.\n",
    "And, after boasting this way of my tolerance, I come to the admission that it has a limit. Conduct may be founded on the hard rock or the wet marshes, but after a certain point I don't care what it's founded on. When I came back from the East last autumn I felt that I wanted the world to be in uniform and at a sort of moral attention forever; I wanted no more riotous excursions with privileged glimpses into the human heart. Only Gatsby, the man who gives his name to this book, was exempt from my reaction -- Gatsby who represented everything for which I have an unaffected scorn.\n",
    "\n",
    "If personality is an unbroken series of successful gestures, then there was something gorgeous about him, some heightened sensitivity to the promises of life, as if he were related to one of those intricate machines that register earthquakes ten thousand miles away. This responsiveness had nothing to do with that flabby impressionability which is dignified under the name of the 'creative temperament' -- it was an extraordinary gift for hope, a romantic readiness such as I have never found in any other person and which it is not likely I shall ever find again. No -- Gatsby turned out all right at the end; it is what preyed on Gatsby, what foul dust floated in the wake of his dreams that temporarily closed out my interest in the abortive sorrows and short-winded elations of men.\n",
    "\n",
    "My family have been prominent, well-to-do people in this Middle Western city for three generations. The Carraways are something of a clan and we have a tradition that we're descended from the Dukes of Buccleuch, but the actual founder of my line was my grandfather's brother who came here in fifty-one, sent a substitute to the Civil War, and started the wholesale hardware business that my father carries on today.\n",
    "\n",
    "I never saw this great-uncle but I'm supposed to look like him -- with special reference to the rather hard-boiled painting that hangs in father's office. I graduated from New Haven in 1915, just a quarter of a century after my father, and a little later I participated in that delayed Teutonic migration known as the Great War. I enjoyed the counter-raid so thoroughly that I came back restless. Instead of being the warm centre of the world, the Middle West now seemed like the ragged edge of the universe -- so I decided to go East and learn the bond business.\n",
    "\n",
    "I enjoyed the counter-raid so thoroughly that I came back restless. Instead of being the warm centre of the world, the Middle West now seemed like the ragged edge of the universe -- so I decided to go East and learn the bond business.\n",
    "\n",
    "Everybody I knew was in the bond business so I supposed it could support one more single man. All my aunts and uncles talked it over as if they were choosing a prep school for me and finally said, 'Why -- ye-es,' with very grave, hesitant faces. Father agreed to finance me for a year and after various delays I came East, permanently, I thought, in the spring of twenty-two.\n",
    "\n",
    "The practical thing was to find rooms in the city but it was a warm season and I had just left a country of wide lawns and friendly trees, so when a young man at the office suggested that we take a house together in a commuting town it sounded like a great idea. He found the house, a weather-beaten cardboard bungalow at eighty a month, but at the last minute the firm ordered him to Washington and I went out to the country alone. I had a dog -- at least I had him for a few days until he ran away -- and an old Dodge and a Finnish woman who made my bed and cooked breakfast and muttered Finnish wisdom to herself over the electric stove.\n",
    "\n",
    "\"\"\"\n",
    "print(pipe(custom_dialogue, **gen_kwargs))"
   ],
   "id": "bea9c842d60fc107",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 25\u001B[0m\n\u001B[0;32m      2\u001B[0m gen_kwargs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlength_penalty\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0.8\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_beams\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m8\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m200\u001B[39m}\n\u001B[0;32m      4\u001B[0m custom_dialogue\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124mIn my younger and more vulnerable years my father gave me some advice that I\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mve been turning over in my mind ever since.\u001B[39m\n\u001B[0;32m      6\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     23\u001B[0m \n\u001B[0;32m     24\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28mprint\u001B[39m(pipe(custom_dialogue, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgen_kwargs))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:269\u001B[0m, in \u001B[0;36mSummarizationPipeline.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    246\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    247\u001B[0m \u001B[38;5;124;03m    Summarize the text(s) given as inputs.\u001B[39;00m\n\u001B[0;32m    248\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    267\u001B[0m \u001B[38;5;124;03m          ids of the summary.\u001B[39;00m\n\u001B[0;32m    268\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 269\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:167\u001B[0m, in \u001B[0;36mText2TextGenerationPipeline.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    139\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001B[39;00m\n\u001B[0;32m    141\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;124;03m          ids of the generated text.\u001B[39;00m\n\u001B[0;32m    165\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 167\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    169\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(args[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mlist\u001B[39m)\n\u001B[0;32m    170\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(el, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m el \u001B[38;5;129;01min\u001B[39;00m args[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m    171\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28mlen\u001B[39m(res) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m result)\n\u001B[0;32m    172\u001B[0m     ):\n\u001B[0;32m    173\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m result]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\transformers\\pipelines\\base.py:1242\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1234\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[0;32m   1235\u001B[0m         \u001B[38;5;28miter\u001B[39m(\n\u001B[0;32m   1236\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_iterator(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1239\u001B[0m         )\n\u001B[0;32m   1240\u001B[0m     )\n\u001B[0;32m   1241\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\transformers\\pipelines\\base.py:1249\u001B[0m, in \u001B[0;36mPipeline.run_single\u001B[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[0m\n\u001B[0;32m   1247\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001B[0;32m   1248\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpreprocess_params)\n\u001B[1;32m-> 1249\u001B[0m     model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(model_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mforward_params)\n\u001B[0;32m   1250\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(model_outputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpostprocess_params)\n\u001B[0;32m   1251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\transformers\\pipelines\\base.py:1149\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[1;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[0;32m   1147\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[0;32m   1148\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m-> 1149\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward(model_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mforward_params)\n\u001B[0;32m   1150\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m   1151\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:191\u001B[0m, in \u001B[0;36mText2TextGenerationPipeline._forward\u001B[1;34m(self, model_inputs, **generate_kwargs)\u001B[0m\n\u001B[0;32m    184\u001B[0m     in_b, input_length \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mshape(model_inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m])\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_inputs(\n\u001B[0;32m    187\u001B[0m     input_length,\n\u001B[0;32m    188\u001B[0m     generate_kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmin_length\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmin_length),\n\u001B[0;32m    189\u001B[0m     generate_kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmax_length),\n\u001B[0;32m    190\u001B[0m )\n\u001B[1;32m--> 191\u001B[0m output_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mgenerate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgenerate_kwargs)\n\u001B[0;32m    192\u001B[0m out_b \u001B[38;5;241m=\u001B[39m output_ids\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\transformers\\generation\\utils.py:1452\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[0;32m   1444\u001B[0m         logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[0;32m   1445\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1446\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeneration results, please set `padding_side=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m` when initializing the tokenizer.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1447\u001B[0m         )\n\u001B[0;32m   1449\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m model_kwargs:\n\u001B[0;32m   1450\u001B[0m     \u001B[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001B[39;00m\n\u001B[0;32m   1451\u001B[0m     \u001B[38;5;66;03m# and added to `model_kwargs`\u001B[39;00m\n\u001B[1;32m-> 1452\u001B[0m     model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_encoder_decoder_kwargs_for_generation(\n\u001B[0;32m   1453\u001B[0m         inputs_tensor, model_kwargs, model_input_name\n\u001B[0;32m   1454\u001B[0m     )\n\u001B[0;32m   1456\u001B[0m \u001B[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001B[39;00m\n\u001B[0;32m   1457\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\transformers\\generation\\utils.py:505\u001B[0m, in \u001B[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001B[1;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001B[0m\n\u001B[0;32m    503\u001B[0m encoder_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreturn_dict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    504\u001B[0m encoder_kwargs[model_input_name] \u001B[38;5;241m=\u001B[39m inputs_tensor\n\u001B[1;32m--> 505\u001B[0m model_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m]: ModelOutput \u001B[38;5;241m=\u001B[39m encoder(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mencoder_kwargs)\n\u001B[0;32m    507\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_kwargs\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1151\u001B[0m, in \u001B[0;36mBartEncoder.forward\u001B[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1148\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1149\u001B[0m     inputs_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_tokens(input_ids) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_scale\n\u001B[1;32m-> 1151\u001B[0m embed_pos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_positions(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m   1152\u001B[0m embed_pos \u001B[38;5;241m=\u001B[39m embed_pos\u001B[38;5;241m.\u001B[39mto(inputs_embeds\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m   1154\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m inputs_embeds \u001B[38;5;241m+\u001B[39m embed_pos\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:132\u001B[0m, in \u001B[0;36mBartLearnedPositionalEmbedding.forward\u001B[1;34m(self, input_ids, past_key_values_length)\u001B[0m\n\u001B[0;32m    127\u001B[0m bsz, seq_len \u001B[38;5;241m=\u001B[39m input_ids\u001B[38;5;241m.\u001B[39mshape[:\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m    128\u001B[0m positions \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39marange(\n\u001B[0;32m    129\u001B[0m     past_key_values_length, past_key_values_length \u001B[38;5;241m+\u001B[39m seq_len, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mdevice\n\u001B[0;32m    130\u001B[0m )\u001B[38;5;241m.\u001B[39mexpand(bsz, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 132\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mforward(positions \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moffset)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 163\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39membedding(\n\u001B[0;32m    164\u001B[0m         \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_idx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_norm,\n\u001B[0;32m    165\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm_type, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale_grad_by_freq, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparse)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\projet-annuel\\Lib\\site-packages\\torch\\nn\\functional.py:2264\u001B[0m, in \u001B[0;36membedding\u001B[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[0;32m   2258\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[0;32m   2259\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[0;32m   2260\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[0;32m   2261\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[0;32m   2262\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[0;32m   2263\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[1;32m-> 2264\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39membedding(weight, \u001B[38;5;28minput\u001B[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001B[1;31mIndexError\u001B[0m: index out of range in self"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "e3ee6a121c03f6ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myJupyterKernel",
   "language": "python",
   "name": "myjupyterkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
