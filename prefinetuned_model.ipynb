{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook destiné à faire du résumé en découpant plusieurs fois un long texte"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8539d5e7fb70f0ac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import du modèle déjà fine tuned"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67caf9aa88e8c222"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from mistral-7b-instruct-v0.2.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4165.37 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 32768\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 1000000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  4096.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 4096.00 MiB, K (f16): 2048.00 MiB, V (f16): 2048.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =  2144.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '1000000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'mistralai_mistral-7b-instruct-v0.2'}\n",
      "Guessed chat format: mistral-instruct\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "llm = Llama(\n",
    "  model_path=\"mistral-7b-instruct-v0.2.Q4_K_M.gguf\",  # Download the model file first\n",
    "  n_ctx=32768,  # The max sequence length to use - note that longer sequence lengths require much more resources\n",
    "  n_threads=4,            # The number of CPU threads to use, tailor to your system and the resulting performance\n",
    "  n_gpu_layers=0         # The number of layers to offload to GPU, if you have GPU acceleration available\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:21:51.880734Z",
     "start_time": "2024-05-09T16:21:46.858845Z"
    }
   },
   "id": "a66328932db8b690"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Définition de l'output attendu"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7b88e4c5c76173c"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   42156.08 ms\n",
      "llama_print_timings:      sample time =      65.33 ms /   193 runs   (    0.34 ms per token,  2954.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =   42154.28 ms /    13 tokens ( 3242.64 ms per token,     0.31 tokens per second)\n",
      "llama_print_timings:        eval time =   76242.51 ms /   192 runs   (  397.10 ms per token,     2.52 tokens per second)\n",
      "llama_print_timings:       total time =  119322.77 ms /   205 tokens\n"
     ]
    }
   ],
   "source": [
    "# Simple inference example\n",
    "output = llm(\n",
    "  \"<s>[INST] {prompt} [/INST]\", # Prompt\n",
    "  max_tokens=512,  # Generate up to 512 tokens\n",
    "  stop=[\"</s>\"],   # Example stop token - not necessarily correct for this specific model! Please check before using.\n",
    "  echo=True        # Whether to echo the prompt\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:24:07.819199Z",
     "start_time": "2024-05-09T16:22:08.399363Z"
    }
   },
   "id": "3430f266ad5ac3f2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test sur une requete"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5aef27e5045698e3"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from ./mistral-7b-instruct-v0.2.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4165.37 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 1000000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    81.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '1000000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'mistralai_mistral-7b-instruct-v0.2'}\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =     141.18 ms /   440 runs   (    0.32 ms per token,  3116.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   35272.22 ms /    37 tokens (  953.30 ms per token,     1.05 tokens per second)\n",
      "llama_print_timings:        eval time =  160457.63 ms /   439 runs   (  365.51 ms per token,     2.74 tokens per second)\n",
      "llama_print_timings:       total time =  197795.66 ms /   476 tokens\n"
     ]
    }
   ],
   "source": [
    "# Chat Completion API\n",
    "\n",
    "llm = Llama(model_path=\"./mistral-7b-instruct-v0.2.Q4_K_M.gguf\", chat_format=\"llama-2\")  # Set chat_format according to the model you are using\n",
    "summary = llm.create_chat_completion(\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You job is to make summaries of long texts.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"summarize harry potter 1\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:46:27.466506Z",
     "start_time": "2024-05-09T16:43:08.777356Z"
    }
   },
   "id": "13480021157206a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sortons uniquement l'ouput de la requete qui nous intéresse"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6823d8f17a8609"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Title: Harry Potter and the Philosopher's Stone (Sorcerer's Stone in some editions)\n",
      "\n",
      "Summary:\n",
      "\n",
      "Harry Potter, an orphan boy living with his abusive aunt and uncle, receives a letter on his eleventh birthday inviting him to attend Hogwarts School of Witchcraft and Wizardry. Unbeknownst to Harry, he is a famous survivor of Voldemort, a dark wizard who had tried to kill him as an infant. At Hogwarts, Harry learns about his magical abilities from his kind mentor, Professor Albus Dumbledore, and makes new friends, Hermione Granger and Ron Weasley.\n",
      "\n",
      "The trio hears rumors of a legendary Philosopher's (Sorcerer's) Stone that can turn any metal into gold and produce the Elixir of Life, granting immortality. Harry learns that Voldemort is after this stone to regain his youth and power. With Dumbledore's guidance, they embark on a quest to protect the stone from falling into Voldemort's hands.\n",
      "\n",
      "The trio faces numerous challenges, including battling trolls, cheating in exams, and dealing with a mischievous house-elf named Dobby. They eventually reach the stone's location in the Chamber of Secrets, where they encounter Tom Riddle, Voldemort's former self, who had been trapped there for centuries. Harry manages to outsmart Riddle and save the day.\n",
      "\n",
      "In the end, Harry returns the Philosopher's Stone to Dumbledore, who uses it to restore the school's damaged library. Harry also learns that Voldemort cannot kill him because a part of Voldemort's soul is connected to Harry through the protective spell cast by Lily Potter, Harry's mother, at the time of his death. This revelation leaves a significant impact on Harry and sets the stage for future events in the series.\n"
     ]
    }
   ],
   "source": [
    "liste_dictionnaires = summary[\"choices\"][0]['message']['content']\n",
    "\n",
    "print(liste_dictionnaires)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:55:24.099443Z",
     "start_time": "2024-05-09T16:55:24.059837Z"
    }
   },
   "id": "86a29913b383840"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fonctions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a24c6305ef44959"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Diviser le texte en segments de 500 caractères ou moins\n",
    "def split_text_into_segments(text, segment_length=1000, instruction=\"make me a short summary of the following text:\"):\n",
    "    segments = []\n",
    "    current_segment = \"\"\n",
    "\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        # Ajouter le mot au segment en cours\n",
    "        current_segment += word + \" \"\n",
    "\n",
    "        # Vérifier si le segment en cours dépasse la longueur maximale\n",
    "        if len(current_segment) >= segment_length:\n",
    "            # Ajouter l'instruction au début du segment\n",
    "            segment_with_instruction = [f\"{instruction} {current_segment.strip()}\"]\n",
    "            # Ajouter le segment complet à la liste des segments\n",
    "            segments.append(segment_with_instruction)\n",
    "            # Réinitialiser le segment en cours\n",
    "            current_segment = \"\"\n",
    "\n",
    "    # Ajouter le segment final s'il n'a pas été ajouté\n",
    "    if current_segment:\n",
    "        # Ajouter l'instruction au début du segment final\n",
    "        segment_with_instruction = [f\"{instruction} {current_segment.strip()}\"]\n",
    "        segments.append(segment_with_instruction)\n",
    "\n",
    "    return segments\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T17:05:20.153478Z",
     "start_time": "2024-05-09T17:05:20.128586Z"
    }
   },
   "id": "74459ea64f54bab2"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# Résumez chaque segment\n",
    "def summarize_text_segments(segments):\n",
    "    summaries = []\n",
    "    for segment in segments:\n",
    "        print(\"start of segment\")\n",
    "        requete = llm.create_chat_completion(\n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": \"You job is to make summaries of long texts.\"},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"{segment}\"\n",
    "                    }\n",
    "                    ]\n",
    "                )\n",
    "        \n",
    "        summary = [requete[\"choices\"][0]['message']['content']]\n",
    "        summaries.append(summary)\n",
    "    return summaries\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:58:33.253884Z",
     "start_time": "2024-05-09T16:58:33.236585Z"
    }
   },
   "id": "4d2cd931427c2393"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# Rassemblez les résumés et résumez-les à nouveau\n",
    "def summarize_summaries(summaries):\n",
    "    concatenated_summaries = \"\"\n",
    "    for summary in summaries:\n",
    "        concatenated_summaries += str(summary) + \" \"\n",
    "    final_summary = llm.create_chat_completion(\n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": \"You job is to make summaries of long texts.\"},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Make me a short summary of this : {concatenated_summaries}\"\n",
    "                    }\n",
    "                    ]\n",
    "                )\n",
    "    return final_summary['choices'][0]['message']['content']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T17:44:23.416839Z",
     "start_time": "2024-05-09T17:44:23.402515Z"
    }
   },
   "id": "4b4921ebf154d901"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Applications à un long texte extrait de livre"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bd958ecbc2ec35b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import d'un dataset contenant des chapitres de livres"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88f3fc840bc04e0c"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"pszemraj/booksum-short\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T17:02:07.057626Z",
     "start_time": "2024-05-09T17:02:05.225534Z"
    }
   },
   "id": "30cb95d3998ec5c9"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# Votre très long texte\n",
    "long_text = dataset[\"train\"][\"chapter\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T17:02:09.273802Z",
     "start_time": "2024-05-09T17:02:08.328366Z"
    }
   },
   "id": "93c9a67a32a0dc99"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### division du long texte en segments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdfdb768754b8414"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# Divisez le texte en segments\n",
    "text_segments = split_text_into_segments(long_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T17:05:25.572669Z",
     "start_time": "2024-05-09T17:05:25.562225Z"
    }
   },
   "id": "e5d9eec73c37fa32"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['make me a short summary of the following text: \"Before these fields were shorn and tilled, Full to the brim our rivers flowed; The melody of waters filled The fresh and boundless wood; And torrents dashed, and rivulets played, And fountains spouted in the shade.\" BRYANT. Leaving the unsuspecting Heyward and his confiding companions to penetrate still deeper into a forest that contained such treacherous inmates, we must use an author\\'s privilege, and shift the scene a few miles to the westward of the place where we have last seen them. On that day, two men were lingering on the banks of a small but rapid stream, within an hour\\'s journey of the encampment of Webb, like those who awaited the appearance of an absent person, or the approach of some expected event. The vast canopy of woods spread itself to the margin of the river overhanging the water, and shadowing its dark current with a deeper hue. The rays of the sun were beginning to grow less fierce, and the intense heat of the day was lessened, as the cooler vapors of the springs']\n"
     ]
    }
   ],
   "source": [
    "print(text_segments[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T17:05:27.797074Z",
     "start_time": "2024-05-09T17:05:27.778808Z"
    }
   },
   "id": "31c25c8e1b6508df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Résumons les différentes parties de ce chapitre"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f22cad3dadf086f3"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      42.58 ms /    84 runs   (    0.51 ms per token,  1972.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =   74919.71 ms /   260 tokens (  288.15 ms per token,     3.47 tokens per second)\n",
      "llama_print_timings:        eval time =   63675.06 ms /    83 runs   (  767.17 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =  139150.16 ms /   343 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      51.25 ms /   124 runs   (    0.41 ms per token,  2419.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   65581.91 ms /   243 tokens (  269.88 ms per token,     3.71 tokens per second)\n",
      "llama_print_timings:        eval time =   60305.41 ms /   123 runs   (  490.29 ms per token,     2.04 tokens per second)\n",
      "llama_print_timings:       total time =  126641.96 ms /   366 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      50.31 ms /   108 runs   (    0.47 ms per token,  2146.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   69449.98 ms /   256 tokens (  271.29 ms per token,     3.69 tokens per second)\n",
      "llama_print_timings:        eval time =   38928.36 ms /   107 runs   (  363.82 ms per token,     2.75 tokens per second)\n",
      "llama_print_timings:       total time =  108926.18 ms /   363 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      38.01 ms /   104 runs   (    0.37 ms per token,  2735.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =   73580.98 ms /   276 tokens (  266.60 ms per token,     3.75 tokens per second)\n",
      "llama_print_timings:        eval time =   41133.03 ms /   103 runs   (  399.35 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =  115340.37 ms /   379 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      46.84 ms /   128 runs   (    0.37 ms per token,  2732.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =   58955.79 ms /   239 tokens (  246.68 ms per token,     4.05 tokens per second)\n",
      "llama_print_timings:        eval time =   45644.96 ms /   127 runs   (  359.41 ms per token,     2.78 tokens per second)\n",
      "llama_print_timings:       total time =  105248.30 ms /   366 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      66.82 ms /   189 runs   (    0.35 ms per token,  2828.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   57665.32 ms /   242 tokens (  238.29 ms per token,     4.20 tokens per second)\n",
      "llama_print_timings:        eval time =   62384.45 ms /   188 runs   (  331.83 ms per token,     3.01 tokens per second)\n",
      "llama_print_timings:       total time =  120988.53 ms /   430 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      34.00 ms /    99 runs   (    0.34 ms per token,  2912.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   76831.36 ms /   254 tokens (  302.49 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:        eval time =   37127.89 ms /    98 runs   (  378.86 ms per token,     2.64 tokens per second)\n",
      "llama_print_timings:       total time =  114424.22 ms /   352 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      30.83 ms /    90 runs   (    0.34 ms per token,  2919.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   70761.21 ms /   249 tokens (  284.18 ms per token,     3.52 tokens per second)\n",
      "llama_print_timings:        eval time =   30569.19 ms /    89 runs   (  343.47 ms per token,     2.91 tokens per second)\n",
      "llama_print_timings:       total time =  101768.44 ms /   338 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      35.23 ms /    94 runs   (    0.37 ms per token,  2668.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   57871.63 ms /   238 tokens (  243.16 ms per token,     4.11 tokens per second)\n",
      "llama_print_timings:        eval time =   31005.16 ms /    93 runs   (  333.39 ms per token,     3.00 tokens per second)\n",
      "llama_print_timings:       total time =   89334.15 ms /   331 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      23.36 ms /    68 runs   (    0.34 ms per token,  2910.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =   61346.27 ms /   254 tokens (  241.52 ms per token,     4.14 tokens per second)\n",
      "llama_print_timings:        eval time =   21888.01 ms /    67 runs   (  326.69 ms per token,     3.06 tokens per second)\n",
      "llama_print_timings:       total time =   83699.44 ms /   321 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      38.85 ms /   104 runs   (    0.37 ms per token,  2676.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =   58896.83 ms /   243 tokens (  242.37 ms per token,     4.13 tokens per second)\n",
      "llama_print_timings:        eval time =   40030.97 ms /   103 runs   (  388.65 ms per token,     2.57 tokens per second)\n",
      "llama_print_timings:       total time =   99447.10 ms /   346 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      42.54 ms /   110 runs   (    0.39 ms per token,  2585.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   61827.87 ms /   249 tokens (  248.30 ms per token,     4.03 tokens per second)\n",
      "llama_print_timings:        eval time =   41341.50 ms /   109 runs   (  379.28 ms per token,     2.64 tokens per second)\n",
      "llama_print_timings:       total time =  103835.95 ms /   358 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      40.65 ms /   117 runs   (    0.35 ms per token,  2878.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   64251.25 ms /   255 tokens (  251.97 ms per token,     3.97 tokens per second)\n",
      "llama_print_timings:        eval time =   40018.26 ms /   116 runs   (  344.99 ms per token,     2.90 tokens per second)\n",
      "llama_print_timings:       total time =  104892.69 ms /   371 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      30.29 ms /    87 runs   (    0.35 ms per token,  2872.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   63321.66 ms /   242 tokens (  261.66 ms per token,     3.82 tokens per second)\n",
      "llama_print_timings:        eval time =   47853.54 ms /    86 runs   (  556.44 ms per token,     1.80 tokens per second)\n",
      "llama_print_timings:       total time =  111590.89 ms /   328 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      40.21 ms /   113 runs   (    0.36 ms per token,  2810.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   79330.68 ms /   273 tokens (  290.59 ms per token,     3.44 tokens per second)\n",
      "llama_print_timings:        eval time =   38408.34 ms /   112 runs   (  342.93 ms per token,     2.92 tokens per second)\n",
      "llama_print_timings:       total time =  118295.85 ms /   385 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      40.22 ms /   112 runs   (    0.36 ms per token,  2784.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =   82086.24 ms /   276 tokens (  297.41 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:        eval time =   54915.86 ms /   111 runs   (  494.74 ms per token,     2.02 tokens per second)\n",
      "llama_print_timings:       total time =  137581.45 ms /   387 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      35.02 ms /   103 runs   (    0.34 ms per token,  2941.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   56839.96 ms /   253 tokens (  224.66 ms per token,     4.45 tokens per second)\n",
      "llama_print_timings:        eval time =   32274.98 ms /   102 runs   (  316.42 ms per token,     3.16 tokens per second)\n",
      "llama_print_timings:       total time =   89581.88 ms /   355 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      25.93 ms /    78 runs   (    0.33 ms per token,  3007.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =   63896.94 ms /   258 tokens (  247.66 ms per token,     4.04 tokens per second)\n",
      "llama_print_timings:        eval time =   29977.48 ms /    77 runs   (  389.32 ms per token,     2.57 tokens per second)\n",
      "llama_print_timings:       total time =   94244.15 ms /   335 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      23.67 ms /    71 runs   (    0.33 ms per token,  2999.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =   47027.00 ms /   201 tokens (  233.97 ms per token,     4.27 tokens per second)\n",
      "llama_print_timings:        eval time =   23103.19 ms /    70 runs   (  330.05 ms per token,     3.03 tokens per second)\n",
      "llama_print_timings:       total time =   70556.14 ms /   271 tokens\n"
     ]
    }
   ],
   "source": [
    "# Résumez chaque segment\n",
    "segment_summaries = summarize_text_segments(text_segments)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T17:39:31.685233Z",
     "start_time": "2024-05-09T17:05:35.365477Z"
    }
   },
   "id": "9afcb76248f4ad7a"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\" In this text, Bryant describes how before being cultivated, rivers flowed abundantly through the woods. Then, the scene shifts to two men waiting by a small rapid stream, near Webb's encampment. They are anticipating someone or an event. The sun's rays are becoming less intense and the heat is decreasing as cooler vapors rise from the springs.\"], [' In a quiet, sultry American landscape in July, two foresters sat near a secluded spot with fountains rising from the foliage. The peaceful scene was interrupted only by the sounds of woodpeckers, jays, and a distant waterfall. Despite these distractions, their attention was focused on their intense dialogue. One forester had native features and wore traditional woodland attire, while the other had sunburnt European descent, hinted through his rugged appearance. The former sat on a mossy log, using expressive gestures to emphasize his words.'], [' A Native American warrior stood before the crowd, nearly naked with a body adorned in contrasting colors of white and black from old wounds. His shaved head, save for a chivalrous scalping tuft and an eagle plume, was bare. He carried a tomahawk, scalping-knife, English rifle, and wore the clothes typical of hardship and exertion. Despite no signs of decay, his muscular build and serious expression suggested he had reached the peak of his strength.'], [\" A hunter or scout is described as having a slender yet muscular build with every nerve and muscle taut from constant exposure and labor. He wears a green hunting shirt, a skin cap without fur, a knife in a wampum girdle, colorful moccasins, buckskin leggings, and a pouch. His only conspicuous weapon is a long rifle leaning against a tree. The hunter's eyes are small, quick, and keen.\"], [\" The text describes a man named Hawk-eye, who speaks to Chingachgook in the native language. Hawk-eye's behavior suggests both suspicion and honesty. He references the past conflicts between their peoples: Hawk-eye's people came from the west over the Hudson River, while Chingachgook's ancestors arrived from the east over the salt lake. Despite their different origins, Hawk-eye argues that they have similar histories of taking land through conflict. He concludes by urging God to decide their current situation based on these shared pasts.\"], [' The text is a dialogue between an unnamed white man and an Indian named Hawkeye. Hawkeye accuses the white man of using lead bullets against the native people, to which the white man questions if there is a difference between the two methods of killing. Hawkeye asserts that there is intelligence in Indians despite their red skin. The white man acknowledges this but then argues that he is not scholarly and that based on his observations at deer chases and squirrel hunts, he believes that the rifles used by the natives\\' grandfathers may have been more dangerous than the lead bullets due to the skill required to use a bow and arrow effectively. Hawkeye ends the conversation by stating \"You have the advantage of me in words; but I question not your honesty.\" (You have the advantage over me in speech, but I do not doubt your sincerity.)'], [\" The speaker recounts a conversation with someone about stories passed down through generations, specifically regarding encounters between white and Native American tribes. The scout acknowledges that he's not biased and admits some faults of his people, including their habit of recording history in books instead of sharing it openly in villages where lies can be challenged. He also mentions that a conscientious man might choose to spend his time learning over women instead of idling away with them.\"], [\" The speaker expresses doubt that the next generation of Bumppos will know or care about their ancestors' accomplishments. He believes his own marksmanship skills are inherited, but is hesitant to speak for others. He asks Chingachgook about the first encounter between their peoples, and after a moment of silence, the Indian begins a solemn retelling of the story as passed down in Mohican tradition.\"], [\" The white man and an Indian discuss the direction of a stream and its change from sweet to saltwater. The white man acknowledges the truth in the Indian's traditions but can't explain why the water becomes bitter in the sun. The Indian insists that his ancestors were not lying when they described the upstream current as a tide, which the white man explains is caused by the six-hour cycle of higher water in the sea flowing into the river.\"], [\" The Indian and the scout discussed the phenomenon of tides. The Indian explained that waters eventually come to rest, but the scout argued that everything depends on the scale one looks at things. While small bodies of water may appear stagnant, larger bodies like the sea cannot be still due to the Earth's round shape.\"], [' The Indian recounted their journey from the land of the setting sun across vast plains inhabited by buffaloes, where they engaged in battle with the Alligewi people near a large river. After defeating them, they claimed the land from the point where water no longer flowed to a distant river, effectively driving the Maquas into the woods and denying them access to the salt lake and fish. The white man listened intently to this narrative and expressed belief in its authenticity.'], [' The speaker, an Indian, reminisced about the past before the English arrived in their country. A pine tree stood where a chestnut now grows, and the first white settlers spoke no English. They came peacefully, and the Indians and whites lived harmoniously, sharing resources and intermarrying. The Indians hunted, fished, and worshipped the Great Spirit. The speaker questioned the white man about his Indian ancestors, acknowledging their bravery and wisdom. The speaker identified himself as a member of the Mohawk tribe.'], [\" The Native American speaker laments the loss of his land to the Dutch settlers, who brought alcohol and sold it to his people, leading them to make hasty decisions. He describes himself as a chief and sagamore, expressing sadness over not being able to visit his ancestors' graves. The scout expresses sympathy and shares that he plans to leave his own bones unburied when he dies. The speaker questions where the previous settlers who came to their land have gone, and laments the passing of time and the loss of his family members.\"], [' The text describes a white man, the last Mohican, on a hilltop lamenting that Uncas, the Indian and the last of his people, will follow him as there will be no more Mohicans left. Suddenly, Uncas appears, and they exchange no words for several minutes before sitting down by a stream. The white man seems to be waiting for the right moment to speak without showing curiosity or impatience.'], [\" Chingachgook, an Indian father, asks if the Iroquois are present in the woods. His son reports seeing their large group but mentions they are hiding. Hawkeye, a white man, warns of French spies and Montcalm's involvement. Chingachgook urges them to eat that night and prepare for battle against the Iroquois the next day. Hawkeye agrees, acknowledging the need to locate the Iroquois first for a fight and to obtain food for eating.\"], [\" A large deer with impressive antlers is spotted by a hunter and an Indian named Uncas. The hunter bets he can shoot the deer between the eyes, closer to the right side. Uncas disagrees, believing only part of the animal is visible. The hunter reveals his experience and assures Uncas that he can determine the deer's location despite only seeing a portion of it. The hunter prepares to take the shot. (Uncas eventually kills the deer by avoiding its horns and slitting its throat.)\"], [\" In the text, Hawkeye, a skilled scout, values his ability highly and initially refuses to fight the Maquas Indians due to their knowledge of the woods. However, when Uncas, his adopted Native American brother, suggests they let the deer go to prevent it from being taken by the Iroquois, Hawkeye agrees. Uncas then successfully hunts the deer using his archery skills, avoiding the infuriated animal's horns and emerging unharmed.\"], [' In the text, a scout successfully kills a deer using a knife after wounding it with an arrow. He expresses satisfaction with his hunting skills and hears approaching footsteps, which he believes belong to wolves following the deer. However, Chingachgook, an Indian companion, corrects him, stating that the sounds are actually from the horses of white men.'], [\" The Native American, standing up with dignity, addressed Hawkeye, telling him to speak to his brothers. Hawkeye agreed and promised to use English so the king wouldn't be embarrassed. Despite not seeing or hearing anyone, Hawkeye believed he heard sounds of people approaching and warned them to stay away from the Iroquois.\"]]\n"
     ]
    }
   ],
   "source": [
    "print(segment_summaries)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T17:39:53.647533Z",
     "start_time": "2024-05-09T17:39:53.535106Z"
    }
   },
   "id": "5ec96f2c69f1e628"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rajoutons une fonction pour regroupe les résumés entre eux, et refaire du résumé de résumé"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da0fabf0594d17"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def group_summaries(summaries, group_size=3):\n",
    "    grouped_summaries = []\n",
    "    current_group = []\n",
    "\n",
    "    for summary_list in summaries:\n",
    "        # Convertir la liste de résumés en une seule chaîne de caractères\n",
    "        summary_string = ' '.join(summary_list)\n",
    "        current_group.append(summary_string)\n",
    "        \n",
    "        if len(current_group) == group_size:\n",
    "            grouped_summaries.append(current_group)\n",
    "            current_group = []\n",
    "\n",
    "    # Ajouter le dernier groupe s'il est incomplet\n",
    "    if current_group:\n",
    "        grouped_summaries.append(current_group)\n",
    "\n",
    "    return grouped_summaries"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T18:03:54.063937Z",
     "start_time": "2024-05-09T18:03:54.051345Z"
    }
   },
   "id": "938818b423125bf6"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "summary_step_2 = group_summaries(segment_summaries)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T18:03:54.617186Z",
     "start_time": "2024-05-09T18:03:54.608636Z"
    }
   },
   "id": "dd19dacc2f1738e"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" The Native American, standing up with dignity, addressed Hawkeye, telling him to speak to his brothers. Hawkeye agreed and promised to use English so the king wouldn't be embarrassed. Despite not seeing or hearing anyone, Hawkeye believed he heard sounds of people approaching and warned them to stay away from the Iroquois.\"]\n"
     ]
    }
   ],
   "source": [
    "print(summary_step_2[6])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T18:04:37.439665Z",
     "start_time": "2024-05-09T18:04:37.423926Z"
    }
   },
   "id": "447b9e5c79b6289a"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      63.88 ms /   166 runs   (    0.38 ms per token,  2598.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   80423.34 ms /   321 tokens (  250.54 ms per token,     3.99 tokens per second)\n",
      "llama_print_timings:        eval time =   71193.77 ms /   165 runs   (  431.48 ms per token,     2.32 tokens per second)\n",
      "llama_print_timings:       total time =  152788.29 ms /   486 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      18.57 ms /    61 runs   (    0.30 ms per token,  3284.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =  117432.04 ms /   425 tokens (  276.31 ms per token,     3.62 tokens per second)\n",
      "llama_print_timings:        eval time =   24899.38 ms /    60 runs   (  414.99 ms per token,     2.41 tokens per second)\n",
      "llama_print_timings:       total time =  142589.01 ms /   485 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      67.21 ms /   200 runs   (    0.34 ms per token,  2975.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   96048.58 ms /   286 tokens (  335.83 ms per token,     2.98 tokens per second)\n",
      "llama_print_timings:        eval time =   67741.94 ms /   199 runs   (  340.41 ms per token,     2.94 tokens per second)\n",
      "llama_print_timings:       total time =  164892.74 ms /   485 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      50.59 ms /   145 runs   (    0.35 ms per token,  2866.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   63738.47 ms /   285 tokens (  223.64 ms per token,     4.47 tokens per second)\n",
      "llama_print_timings:        eval time =   52466.32 ms /   144 runs   (  364.35 ms per token,     2.74 tokens per second)\n",
      "llama_print_timings:       total time =  116984.32 ms /   429 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      52.89 ms /   151 runs   (    0.35 ms per token,  2855.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   85227.76 ms /   319 tokens (  267.17 ms per token,     3.74 tokens per second)\n",
      "llama_print_timings:        eval time =   52091.57 ms /   150 runs   (  347.28 ms per token,     2.88 tokens per second)\n",
      "llama_print_timings:       total time =  138227.23 ms /   469 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      63.25 ms /   177 runs   (    0.36 ms per token,  2798.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   81521.74 ms /   298 tokens (  273.56 ms per token,     3.66 tokens per second)\n",
      "llama_print_timings:        eval time =   71374.25 ms /   176 runs   (  405.54 ms per token,     2.47 tokens per second)\n",
      "llama_print_timings:       total time =  153966.22 ms /   474 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      25.91 ms /    64 runs   (    0.40 ms per token,  2469.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   27498.35 ms /    74 tokens (  371.60 ms per token,     2.69 tokens per second)\n",
      "llama_print_timings:        eval time =   23553.18 ms /    63 runs   (  373.86 ms per token,     2.67 tokens per second)\n",
      "llama_print_timings:       total time =   51599.80 ms /   137 tokens\n"
     ]
    }
   ],
   "source": [
    "# Résumez chaque segment\n",
    "segment_summaries_2 = summarize_text_segments(summary_step_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T18:20:06.501729Z",
     "start_time": "2024-05-09T18:04:44.893647Z"
    }
   },
   "id": "d3045e78ba8bd53c"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\" The text describes two scenes in an American landscape in July. In the first scene, rivers flowed abundantly through the woods before being cultivated. Two men are waiting near a small rapid stream, anticipating someone or an event. The sun's heat is decreasing as cooler vapors rise from the springs.\\n\\nIn the second scene, two foresters sit in a quiet, sultry landscape with fountains rising from the foliage. They are engaged in an intense dialogue, interrupted only by the sounds of woodpeckers, jays, and a distant waterfall. One forester has native features and wears traditional woodland attire, while the other has sunburnt European descent.\\n\\nIn another scene, a Native American warrior stands before a crowd, nearly naked\"], [' The text describes a hunter with a lean, muscular build and keen eyes. He wears traditional hunting gear and carries a long rifle. Hawk-eye, the hunter, speaks to Chingachgook in their native language. They discuss their shared histories of conflict over land'], [\" In the conversation between a speaker and an unnamed Native American scout named Chingachgook, they discuss stories passed down through generations about encounters between their peoples. The scout acknowledges his people's faults, including their tendency to record history in books instead of sharing it openly in villages where lies can be challenged. He also mentions that some conscientious men might choose to spend their time learning over idling away with women.\\n\\nThe speaker expresses doubt that the next generation will know or care about their ancestors' accomplishments. The speaker shares his belief that his marksmanship skills are inherited, but is hesitant to speak for others. He asks Chingachgook about the first encounter between their peoples, and after a moment of silence, the Indian begins a solemn retelling of the story as passed down in Mohican tradition.\\n\\nThey also discuss the direction of a stream and its change from sweet to saltwater\"], [\" Summary 1: The Indian and the scout had a conversation about tides, with the Indian explaining that even large bodies of water eventually come to rest while the scout argued that this depends on one's perspective. They then shared stories of their past experiences, including journeys, battles, and interactions with white settlers.\\n\\nSummary 2: The speaker, an Indian, shared memories of life before European arrival in their land. He described a time when a pine tree stood where a chestnut now grows and when the first white settlers came peacefully and intermarried with Indians. The speaker identified himself as a Mohawk and expressed admiration for the bravery and wisdom of white ancestors.\"], [' In the first text, a Native American speaker mourns the loss of his land to Dutch settlers, expressing sadness over the sale of alcohol that led his people to make hasty decisions. He identifies himself as a chief and sagamore, lamenting the inability to visit ancestral graves and questioning the whereabouts of previous settlers. In the second text, Chingachgook, an Indian father, asks about the presence of Iroquois in the woods while his son reports seeing them hiding. Hawkeye, a white man, warns of French spies and advises preparation for battle against the Iroquois the next day, emphasizing the importance of locating them first.'], [\" A hunter and an Indian named Uncas argue over the location of a large deer with impressive antlers. The hunter bets he can shoot it between the eyes from a partial view, while Uncas believes only part of the animal is visible. The hunter, confident in his skills, prepares to take the shot. In another instance, Hawkeye, a skilled scout, initially refuses to fight Maquas Indians due to their knowledge of the woods. However, he agrees to let a deer go with Uncas' suggestion. Uncas then successfully hunts the deer using his archery skills and kills it with a knife. Later, Hawkeye hears approaching footsteps and believes they belong to wolves following the deer, but Chingachgook corrects him, revealing that the sounds are actually from white men on horses.\"], [\" A Native American speaker addressed Hawkeye, asking him to communicate with his brothers. Hawkeye agreed and promised to use English to avoid embarrassing the king. Although he didn't see or hear anyone, Hawkeye believed he heard approaching sounds and warned the Iroquois to keep their distance.\"]]\n"
     ]
    }
   ],
   "source": [
    "print(segment_summaries_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T18:21:16.770967Z",
     "start_time": "2024-05-09T18:21:16.723640Z"
    }
   },
   "id": "be8883ed9bcdc0fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### notre résumé est toujours trop long par rapport à nos max tokens du débuts, réduisons encore"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cc471c6053fbf51"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "# Résumez chaque segment\n",
    "summaries_step_3 = group_summaries(segment_summaries_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T18:26:20.412788Z",
     "start_time": "2024-05-09T18:26:20.391612Z"
    }
   },
   "id": "8a83a99dca0f9624"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" A Native American speaker addressed Hawkeye, asking him to communicate with his brothers. Hawkeye agreed and promised to use English to avoid embarrassing the king. Although he didn't see or hear anyone, Hawkeye believed he heard approaching sounds and warned the Iroquois to keep their distance.\"]\n"
     ]
    }
   ],
   "source": [
    "print(summaries_step_3[2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T18:25:58.912093Z",
     "start_time": "2024-05-09T18:25:58.897451Z"
    }
   },
   "id": "438b46c43b2f78e8"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      32.66 ms /    46 runs   (    0.71 ms per token,  1408.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =  107146.50 ms /   439 tokens (  244.07 ms per token,     4.10 tokens per second)\n",
      "llama_print_timings:        eval time =  281113.72 ms /    45 runs   ( 6246.97 ms per token,     0.16 tokens per second)\n",
      "llama_print_timings:       total time =  388823.64 ms /   484 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /     9 runs   (    0.40 ms per token,  2511.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =  113840.93 ms /   477 tokens (  238.66 ms per token,     4.19 tokens per second)\n",
      "llama_print_timings:        eval time =    4608.02 ms /     8 runs   (  576.00 ms per token,     1.74 tokens per second)\n",
      "llama_print_timings:       total time =  118509.57 ms /   485 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      28.25 ms /    66 runs   (    0.43 ms per token,  2336.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21279.12 ms /    67 tokens (  317.60 ms per token,     3.15 tokens per second)\n",
      "llama_print_timings:        eval time =   46082.94 ms /    65 runs   (  708.97 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   67849.22 ms /   132 tokens\n"
     ]
    }
   ],
   "source": [
    "# Résumez chaque segment\n",
    "segment_summaries_3 = summarize_text_segments(summaries_step_3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T18:36:20.294125Z",
     "start_time": "2024-05-09T18:26:44.781211Z"
    }
   },
   "id": "c7233266d5e179a8"
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   35272.35 ms\n",
      "llama_print_timings:      sample time =      46.18 ms /    90 runs   (    0.51 ms per token,  1948.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   47982.18 ms /   139 tokens (  345.20 ms per token,     2.90 tokens per second)\n",
      "llama_print_timings:        eval time =   42846.28 ms /    89 runs   (  481.42 ms per token,     2.08 tokens per second)\n",
      "llama_print_timings:       total time =   91775.57 ms /   228 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In the first part of the text, two scenes in an American landscape in July are described: men waiting by a small river as cool vapors rise from springs due to decreasing heat. In the second part, a Native American speaker asks Hawkeye to deliver a message to his brothers using English to avoid embarrassment for their chief. Hawkeye agrees and senses approaching sounds, urging caution for the Iroquois.\n"
     ]
    }
   ],
   "source": [
    "# Résumez les résumés\n",
    "final_summary = summarize_summaries(segment_summaries_3)\n",
    "\n",
    "print(final_summary)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T18:37:58.436821Z",
     "start_time": "2024-05-09T18:36:26.552841Z"
    }
   },
   "id": "a69753b25d8164fc"
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  \"Before these fields were shorn and tilled,\n",
      "    Full to the brim our rivers flowed;\n",
      "  The melody of waters filled\n",
      "    The fresh and boundless wood;\n",
      "  And torrents dashed, and rivulets played,\n",
      "    And fountains spouted in the shade.\"\n",
      "\n",
      "  BRYANT.\n",
      "\n",
      "\n",
      "Leaving the unsuspecting Heyward and his confiding companions to\n",
      "penetrate still deeper into a forest that contained such treacherous\n",
      "inmates, we must use an author's privilege, and shift the scene a few\n",
      "miles to the westward of the place where we have last seen them.\n",
      "\n",
      "On that day, two men were lingering on the banks of a small but rapid\n",
      "stream, within an hour's journey of the encampment of Webb, like those\n",
      "who awaited the appearance of an absent person, or the approach of some\n",
      "expected event. The vast canopy of woods spread itself to the margin of\n",
      "the river overhanging the water, and shadowing its dark current with a\n",
      "deeper hue. The rays of the sun were beginning to grow less fierce, and\n",
      "the intense heat of the day was lessened, as the cooler vapors of the\n",
      "springs and fountains rose above their leafy beds, and rested in the\n",
      "atmosphere. Still that breathing silence, which marks the drowsy\n",
      "sultriness of an American landscape in July, pervaded the secluded spot,\n",
      "interrupted only by the low voices of the men, the occasional and lazy\n",
      "tap of a woodpecker, the discordant cry of some gaudy jay, or a swelling\n",
      "on the ear, from the dull roar of a distant waterfall.\n",
      "\n",
      "These feeble and broken sounds were, however, too familiar to the\n",
      "foresters, to draw their attention from the more interesting matter of\n",
      "their dialogue. While one of these loiterers showed the red skin and\n",
      "wild accoutrements of a native of the woods, the other exhibited,\n",
      "through the mask of his rude and nearly savage equipments, the brighter,\n",
      "though sunburnt and long-faded complexion of one who might claim descent\n",
      "from a European parentage. The former was seated on the end of a mossy\n",
      "log, in a posture that permitted him to heighten the effect of his\n",
      "earnest language, by the calm but expressive gestures of an Indian\n",
      "engaged in debate. His body, which was nearly naked, presented a\n",
      "terrific emblem of death, drawn in intermingled colors of white and\n",
      "black. His closely shaved head, on which no other hair than the well\n",
      "known and chivalrous scalping tuft[5] was preserved, was without\n",
      "ornament of any kind, with the exception of a solitary eagle's plume,\n",
      "that crossed his crown, and depended over the left shoulder. A tomahawk\n",
      "and scalping-knife, of English manufacture, were in his girdle; while a\n",
      "short military rifle, of that sort with which the policy of the whites\n",
      "armed their savage allies, lay carelessly across his bare and sinewy\n",
      "knee. The expanded chest, full formed limbs, and grave countenance of\n",
      "this warrior, would denote that he had reached the vigor of his days,\n",
      "though no symptoms of decay appeared to have yet weakened his manhood.\n",
      "\n",
      "The frame of the white man, judging by such parts as were not concealed\n",
      "by his clothes, was like that of one who had known hardships and\n",
      "exertion from his earliest youth. His person, though muscular, was\n",
      "rather attenuated than full; but every nerve and muscle appeared strung\n",
      "and indurated by unremitted exposure and toil. He wore a hunting-shirt\n",
      "of forest green, fringed with faded yellow[6], and a summer cap of skins\n",
      "which had been shorn of their fur. He also bore a knife in a girdle of\n",
      "wampum, like that which confined the scanty garments of the Indian, but\n",
      "no tomahawk. His moccasins were ornamented after the gay fashion of the\n",
      "natives, while the only part of his under-dress which appeared below the\n",
      "hunting-frock, was a pair of buckskin leggings, that laced at the sides,\n",
      "and which were gartered above the knees with the sinews of a deer. A\n",
      "pouch and horn completed his personal accoutrements, though a rifle of\n",
      "great length[7], which the theory of the more ingenious whites had\n",
      "taught them was the most dangerous of all fire-arms, leaned against a\n",
      "neighboring sapling. The eye of the hunter, or scout, whichever he might\n",
      "be, was small, quick, keen, and restless, roving while he spoke, on\n",
      "every side of him, as if in quest of game, or distrusting the sudden\n",
      "approach of some lurking enemy. Notwithstanding the symptoms of habitual\n",
      "suspicion, his countenance was not only without guile, but at the moment\n",
      "at which he is introduced, it was charged with an expression of sturdy\n",
      "honesty.\n",
      "\n",
      "\"Even your traditions make the case in my favor, Chingachgook,\" he said,\n",
      "speaking in the tongue which was known to all the natives who formerly\n",
      "inhabited the country between the Hudson and the Potomac, and of which\n",
      "we shall give a free translation for the benefit of the reader;\n",
      "endeavoring, at the same time, to preserve some of the peculiarities,\n",
      "both of the individual and of the language. \"Your fathers came from the\n",
      "setting sun, crossed the big river,[8] fought the people of the country,\n",
      "and took the land; and mine came from the red sky of the morning, over\n",
      "the salt lake, and did their work much after the fashion that had been\n",
      "set them by yours; then let God judge the matter between us, and friends\n",
      "spare their words!\"\n",
      "\n",
      "\"My fathers fought with the naked redmen!\" returned the Indian sternly,\n",
      "in the same language. \"Is there no difference, Hawkeye, between the\n",
      "stone-headed arrow of the warrior, and the leaden bullet with which you\n",
      "kill?\"\n",
      "\n",
      "\"There is reason in an Indian, though nature has made him with a red\n",
      "skin!\" said the white man, shaking his head like one on whom such an\n",
      "appeal to his justice was not thrown away. For a moment he appeared to\n",
      "be conscious of having the worst of the argument, then, rallying again,\n",
      "he answered the objection of his antagonist in the best manner his\n",
      "limited information would allow: \"I am no scholar, and I care not who\n",
      "knows it; but judging from what I have seen, at deer chases and squirrel\n",
      "hunts, of the sparks below, I should think a rifle in the hands of their\n",
      "grandfathers was not so dangerous as a hickory bow and a good flint-head\n",
      "might be, if drawn with Indian judgment, and sent by an Indian eye.\"\n",
      "\n",
      "\"You have the story told by your fathers,\" returned the other, coldly\n",
      "waving his hand. \"What say your old men? do they tell the young\n",
      "warriors, that the pale-faces met the redmen, painted for war and armed\n",
      "with the stone hatchet and wooden gun?\"\n",
      "\n",
      "\"I am not a prejudiced man, nor one who vaunts himself on his natural\n",
      "privileges, though the worst enemy I have on earth, and he is an\n",
      "Iroquois, daren't deny that I am genuine white,\" the scout replied,\n",
      "surveying, with secret satisfaction, the faded color of his bony and\n",
      "sinewy hand; \"and I am willing to own that my people have many ways, of\n",
      "which, as an honest man, I can't approve. It is one of their customs to\n",
      "write in books what they have done and seen, instead of telling them in\n",
      "their villages, where the lie can be given to the face of a cowardly\n",
      "boaster, and the brave soldier can call on his comrades to witness for\n",
      "the truth of his words. In consequence of this bad fashion, a man who is\n",
      "too conscientious to misspend his days among the women, in learning the\n",
      "names of black marks, may never hear of the deeds of his fathers, nor\n",
      "feel a pride in striving to outdo them. For myself, I conclude the\n",
      "Bumppos could shoot, for I have a natural turn with a rifle, which must\n",
      "have been handed down from generation to generation, as, our holy\n",
      "commandments tell us, all good and evil gifts are bestowed; though I\n",
      "should be loth to answer for other people in such a matter. But every\n",
      "story has its two sides; so I ask you, Chingachgook, what passed,\n",
      "according to the traditions of the redmen, when our fathers first met?\"\n",
      "\n",
      "A silence of a minute succeeded, during which the Indian sat mute; then,\n",
      "full of the dignity of his office, he commenced his brief tale, with a\n",
      "solemnity that served to heighten its appearance of truth.\n",
      "\n",
      "\"Listen, Hawkeye, and your ear shall drink no lie. 'Tis what my fathers\n",
      "have said, and what the Mohicans have done.\" He hesitated a single\n",
      "instant, and bending a cautious glance toward his companion, he\n",
      "continued, in a manner that was divided between interrogation and\n",
      "assertion, \"Does not this stream at our feet run towards the summer,\n",
      "until its waters grow salt, and the current flows upward?\"\n",
      "\n",
      "\"It can't be denied that your traditions tell you true in both these\n",
      "matters,\" said the white man; \"for I have been there, and have seen\n",
      "them; though, why water, which is so sweet in the shade, should become\n",
      "bitter in the sun, is an alteration for which I have never been able to\n",
      "account.\"\n",
      "\n",
      "\"And the current!\" demanded the Indian, who expected his reply with that\n",
      "sort of interest that a man feels in the confirmation of testimony, at\n",
      "which he marvels even while he respects it; \"the fathers of Chingachgook\n",
      "have not lied!\"\n",
      "\n",
      "\"The Holy Bible is not more true, and that is the truest thing in\n",
      "nature. They call this up-stream current the tide, which is a thing soon\n",
      "explained, and clear enough. Six hours the waters run in, and six hours\n",
      "they run out, and the reason is this: when there is higher water in the\n",
      "sea than in the river, they run in, until the river gets to be highest,\n",
      "and then it runs out again.\"\n",
      "\n",
      "\"The waters in the woods, and on the great lakes, run downward until\n",
      "they lie like my hand,\" said the Indian, stretching the limb\n",
      "horizontally before him, \"and then they run no more.\"\n",
      "\n",
      "\"No honest man will deny it,\" said the scout, a little nettled at the\n",
      "implied distrust of his explanation of the mystery of the tides; \"and I\n",
      "grant that it is true on the small scale, and where the land is level.\n",
      "But everything depends on what scale you look at things. Now, on the\n",
      "small scale, the 'arth is level; but on the large scale it is round. In\n",
      "this manner, pools and ponds, and even the great fresh-water lake, may\n",
      "be stagnant, as you and I both know they are, having seen them; but when\n",
      "you come to spread water over a great tract, like the sea, where the\n",
      "earth is round, how in reason can the water be quiet? You might as well\n",
      "expect the river to lie still on the brink of those black rocks a mile\n",
      "above us, though your own ears tell you that it is tumbling over them at\n",
      "this very moment!\"\n",
      "\n",
      "If unsatisfied by the philosophy of his companion, the Indian was far\n",
      "too dignified to betray his unbelief. He listened like one who was\n",
      "convinced, and resumed his narrative in his former solemn manner.\n",
      "\n",
      "\"We came from the place where the sun is hid at night, over great plains\n",
      "where the buffaloes live, until we reached the big river. There we\n",
      "fought the Alligewi, till the ground was red with their blood. From the\n",
      "banks of the big river to the shores of the salt lake, there was none to\n",
      "meet us. The Maquas followed at a distance. We said the country should\n",
      "be ours from the place where the water runs up no longer on this stream,\n",
      "to a river twenty suns' journey toward the summer. The land we had taken\n",
      "like warriors, we kept like men. We drove the Maquas into the woods with\n",
      "the bears. They only tasted salt at the licks; they drew no fish from\n",
      "the great lake; we threw them the bones.\"\n",
      "\n",
      "\"All this I have heard and believe,\" said the white man, observing that\n",
      "the Indian paused: \"but it was long before the English came into the\n",
      "country.\"\n",
      "\n",
      "\"A pine grew then where this chestnut now stands. The first pale-faces\n",
      "who came among us spoke no English. They came in a large canoe, when my\n",
      "fathers had buried the tomahawk with the redmen around them. Then,\n",
      "Hawkeye,\" he continued, betraying his deep emotion only by permitting\n",
      "his voice to fall to those low, guttural tones, which rendered his\n",
      "language, as spoken at times, so very musical; \"then, Hawkeye, we were\n",
      "one people, and we were happy. The salt lake gave us its fish, the wood\n",
      "its deer, and the air its birds. We took wives who bore us children; we\n",
      "worshipped the Great Spirit; and we kept the Maquas beyond the sound of\n",
      "our songs of triumph!\"\n",
      "\n",
      "\"Know you anything of your own family at that time?\" demanded the white.\n",
      "\"But you are a just man, for an Indian! and, as I suppose you hold their\n",
      "gifts, your fathers must have been brave warriors, and wise men at the\n",
      "council fire.\"\n",
      "\n",
      "\"My tribe is the grandfather of nations, but I am an unmixed man. The\n",
      "blood of chiefs is in my veins, where it must stay forever. The Dutch\n",
      "landed, and gave my people the fire-water; they drank until the heavens\n",
      "and the earth seemed to meet, and they foolishly thought they had found\n",
      "the Great Spirit. Then they parted with their land. Foot by foot, they\n",
      "were driven back from the shores, until I, that am a chief and a\n",
      "sagamore, have never seen the sun shine but through the trees, and have\n",
      "never visited the graves of, my fathers!\"\n",
      "\n",
      "\"Graves bring solemn feelings over the mind,\" returned the scout, a good\n",
      "deal touched at the calm suffering of his companion; \"and they often aid\n",
      "a man in his good intentions; though, for myself, I expect to leave my\n",
      "own bones unburied, to bleach in the woods, or to be torn asunder by the\n",
      "wolves. But where are to be found those of your race who came to their\n",
      "kin in the Delaware country, so many summers since?\"\n",
      "\n",
      "\"Where are the blossoms of those summers!--fallen, one by one: so all of\n",
      "my family departed, each in his turn, to the land of spirits. I am on\n",
      "the hill-top, and must go down into the valley; and when Uncas follows\n",
      "in my footsteps, there will no longer be any of the blood of the\n",
      "sagamores, for my boy is the last of the Mohicans.\"\n",
      "\n",
      "\"Uncas is here!\" said another voice, in the same soft, guttural tones,\n",
      "near his elbow; \"who speaks to Uncas?\"\n",
      "\n",
      "The white man loosened his knife in his leathern sheath, and made an\n",
      "involuntary movement of the hand towards his rifle, at this sudden\n",
      "interruption; but the Indian sat composed, and without turning his head\n",
      "at the unexpected sounds.\n",
      "\n",
      "At the next instant, a youthful warrior passed between them, with a\n",
      "noiseless step, and seated himself on the bank of the rapid stream. No\n",
      "exclamation of surprise escaped the father, nor was any question asked,\n",
      "or reply given, for several minutes; each appearing to await the moment\n",
      "when he might speak, without betraying womanish curiosity or childish\n",
      "impatience. The white man seemed to take counsel from their customs,\n",
      "and, relinquishing his grasp of the rifle, he also remained silent and\n",
      "reserved. At length Chingachgook turned his eyes slowly towards his son,\n",
      "and demanded,--\n",
      "\n",
      "\"Do the Maquas dare to leave the print of their moccasins in these\n",
      "woods?\"\n",
      "\n",
      "\"I have been on their trail,\" replied the young Indian, \"and know that\n",
      "they number as many as the fingers of my two hands; but they lie hid,\n",
      "like cowards.\"\n",
      "\n",
      "\"The thieves are outlying for scalps and plunder!\" said the white man,\n",
      "whom we shall call Hawkeye, after the manner of his companions. \"That\n",
      "bushy Frenchman, Montcalm, will send his spies into our very camp, but\n",
      "he will know what road we travel!\"\n",
      "\n",
      "\"Tis enough!\" returned the father, glancing his eye towards the setting\n",
      "sun; \"they shall be driven like deer from their bushes. Hawkeye, let us\n",
      "eat to-night, and show the Maquas that we are men to-morrow.\"\n",
      "\n",
      "\"I am as ready to do the one as the other; but to fight the Iroquois\n",
      "'tis necessary to find the skulkers; and to eat, 'tis necessary to get\n",
      "the game--talk of the devil and he will come; there is a pair of the\n",
      "biggest antlers I have seen this season, moving the bushes below the\n",
      "hill! Now, Uncas,\" he continued in a half whisper, and laughing with a\n",
      "kind of inward sound, like one who had learnt to be watchful, \"I will\n",
      "bet my charger three times full of powder, against a foot of wampum,\n",
      "that I take him atwixt the eyes, and nearer to the right than to the\n",
      "left.\"\n",
      "\n",
      "\"It cannot be!\" said the young Indian, springing to his feet with\n",
      "youthful eagerness; \"all but the tips of his horns are hid!\"\n",
      "\n",
      "\"He's a boy!\" said the white man, shaking his head while he spoke, and\n",
      "addressing the father. \"Does he think when a hunter sees a part of the\n",
      "creatur', he can't tell where the rest of him should be!\"\n",
      "\n",
      "[Illustration: _Copyright by Charles Scribner's Sons_\n",
      "\n",
      "UNCAS SLAYS A DEER\n",
      "\n",
      "_Avoiding the horns of the infuriated animal, Uncas darted to his side,\n",
      "and passed his knife across the throat_]\n",
      "\n",
      "Adjusting his rifle, he was about to make an exhibition of that skill,\n",
      "on which he so much valued himself, when the warrior struck up the piece\n",
      "with his hand, saying--\n",
      "\n",
      "\"Hawkeye! will you fight the Maquas?\"\n",
      "\n",
      "\"These Indians know the nature of the woods, as it might be by\n",
      "instinct!\" returned the scout, dropping his rifle, and turning away like\n",
      "a man who was convinced of his error. \"I must leave the buck to your\n",
      "arrow, Uncas, or we may kill a deer for them thieves, the Iroquois, to\n",
      "eat.\"\n",
      "\n",
      "The instant the father seconded this intimation by an expressive gesture\n",
      "of the hand, Uncas threw himself on the ground, and approached the\n",
      "animal with wary movements. When within a few yards of the cover, he\n",
      "fitted an arrow to his bow with the utmost care, while the antlers\n",
      "moved, as if their owner snuffed an enemy in the tainted air. In another\n",
      "moment the twang of the cord was heard, a white streak was seen glancing\n",
      "into the bushes, and the wounded buck plunged from the cover, to the\n",
      "very feet of his hidden enemy. Avoiding the horns of the infuriated\n",
      "animal, Uncas darted to his side, and passed his knife across the\n",
      "throat, when bounding to the edge of the river it fell, dyeing the\n",
      "waters with its blood.\n",
      "\n",
      "\"'Twas done with Indian skill,\" said the scout, laughing inwardly, but\n",
      "with vast satisfaction; \"and 'twas a pretty sight to behold! Though an\n",
      "arrow is a near shot, and needs a knife to finish the work.\"\n",
      "\n",
      "\"Hugh!\" ejaculated his companion, turning quickly, like a hound who\n",
      "scented game.\n",
      "\n",
      "\"By the Lord, there is a drove of them!\" exclaimed the scout, whose eyes\n",
      "began to glisten with the ardor of his usual occupation; \"if they come\n",
      "within range of a bullet I will drop one, though the whole Six Nations\n",
      "should be lurking within sound! What do you hear, Chingachgook? for to\n",
      "my ears the woods are dumb.\"\n",
      "\n",
      "\"There is but one deer, and he is dead,\" said the Indian, bending his\n",
      "body till his ear nearly touched the earth. \"I hear the sounds of feet!\"\n",
      "\n",
      "\"Perhaps the wolves have driven the buck to shelter, and are following\n",
      "on his trail.\"\n",
      "\n",
      "\"No. The horses of white men are coming!\" returned the other, raising\n",
      "himself with dignity, and resuming his seat on the log with his former\n",
      "composure. \"Hawkeye, they are your brothers; speak to them.\"\n",
      "\n",
      "\"That will I, and in English that the king needn't be ashamed to\n",
      "answer,\" returned the hunter, speaking in the language of which he\n",
      "boasted; \"but I see nothing, nor do I hear the sounds of man or beast;\n",
      "'tis strange that an Indian should understand white sounds better than a\n",
      "man who, his very enemies will own, has no cross in his blood, although\n",
      "he may have lived with the redskins long enough to be suspected! Ha!\n",
      "there goes something like the cracking of a dry stick, too--now I hear\n",
      "the bushes move--yes, yes, there is a trampling that I mistook for the\n",
      "falls--and--but here they come themselves; God keep them from the\n",
      "Iroquois!\"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(long_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T18:39:04.970240Z",
     "start_time": "2024-05-09T18:39:04.926553Z"
    }
   },
   "id": "d2a4e7e5aff1a41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e99b344ec8f67013"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
