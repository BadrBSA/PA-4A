{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:31:33.997137100Z",
     "start_time": "2024-04-19T21:31:33.866174200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading readme:   0%|          | 0.00/750 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "221e76164bd6446eb990a34fc7dcf3e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 126M/126M [00:05<00:00, 25.0MB/s] \n",
      "Downloading data: 100%|██████████| 22.2M/22.2M [00:01<00:00, 11.3MB/s]\n",
      "Downloading data: 100%|██████████| 19.0M/19.0M [00:03<00:00, 5.62MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c62cf87a1388426fa5444090387aad6a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating validation split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b4c7d98023f4b95959750739ffc7427"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14a61f11062e4c5e8b4524b41304a667"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"pszemraj/booksum-short\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T20:44:39.721164Z",
     "start_time": "2024-04-19T20:44:23.893555800Z"
    }
   },
   "id": "7263fc51f1ae225f"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=True,\n",
    "        llm_int8_enable_fp32_cpu_offload=True,\n",
    "        # llm_int8_has_fp16_weight=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=\"float16\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:06:43.009047Z",
     "start_time": "2024-04-19T21:06:43.004186500Z"
    }
   },
   "id": "261dd87971875d73"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:06:43.964543Z",
     "start_time": "2024-04-19T21:06:43.960069Z"
    }
   },
   "id": "89ea41671bac7df1"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b96e21180614048b6e0de1d59842b55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", quantization_config=quantization_config, device_map=\"auto\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:07:07.032370300Z",
     "start_time": "2024-04-19T21:06:44.622253800Z"
    }
   },
   "id": "1a28c0ec89c553f3"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:07:07.290785100Z",
     "start_time": "2024-04-19T21:07:07.041408800Z"
    }
   },
   "id": "23934443aa3ee2a3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is your favourite condiment?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T20:19:08.591175800Z",
     "start_time": "2024-04-19T20:19:08.585529700Z"
    }
   },
   "id": "992cca422d0efe21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "model_inputs = encodeds.to(device)\n",
    "# model.to(device)\n",
    "\n",
    "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-19T20:31:44.806166400Z"
    }
   },
   "id": "b4daafb425acfd93"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"].select_columns(['chapter', 'summary'])\n",
    "val_dataset = dataset[\"validation\"].select_columns(['chapter', 'summary'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:03:36.004468100Z",
     "start_time": "2024-04-19T21:03:35.992905700Z"
    }
   },
   "id": "b17151a120d20d86"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['chapter', 'summary'],\n",
      "    num_rows: 5912\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:03:55.102149Z",
     "start_time": "2024-04-19T21:03:55.097120500Z"
    }
   },
   "id": "82ddcf8f14a29e68"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['bid', 'is_aggregate', 'source', 'chapter_path', 'summary_path', 'book_id', 'summary_id', 'content', 'summary', 'chapter', 'chapter_length', 'summary_name', 'summary_url', 'summary_text', 'summary_analysis', 'summary_length', 'analysis_length'],\n",
      "        num_rows: 5912\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['bid', 'is_aggregate', 'source', 'chapter_path', 'summary_path', 'book_id', 'summary_id', 'content', 'summary', 'chapter', 'chapter_length', 'summary_name', 'summary_url', 'summary_text', 'summary_analysis', 'summary_length', 'analysis_length'],\n",
      "        num_rows: 1012\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['bid', 'is_aggregate', 'source', 'chapter_path', 'summary_path', 'book_id', 'summary_id', 'content', 'summary', 'chapter', 'chapter_length', 'summary_name', 'summary_url', 'summary_text', 'summary_analysis', 'summary_length', 'analysis_length'],\n",
      "        num_rows: 988\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T20:49:55.291098500Z",
     "start_time": "2024-04-19T20:49:55.286517600Z"
    }
   },
   "id": "67ac210affa99d5e"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def encode(dataset):\n",
    "    return tokenizer(dataset[\"chapter\"], dataset[\"summary\"], truncation=True, padding=\"max_length\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:06:19.711001500Z",
     "start_time": "2024-04-19T21:06:19.703394500Z"
    }
   },
   "id": "a21c8d680b03aa8f"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/5912 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e3f838ec1634d4580edbf2ec8820247"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73411ff12ae14e8289b2f5a8cc8c7280"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_train_dataset = train_dataset.map(encode, batched=True)\n",
    "encoded_val_dataset = val_dataset.map(encode, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:36:21.797783200Z",
     "start_time": "2024-04-19T21:35:55.539113900Z"
    }
   },
   "id": "21b6dcf401ac90a"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['chapter', 'summary', 'input_ids', 'attention_mask'],\n    num_rows: 5912\n})"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:36:21.804512Z",
     "start_time": "2024-04-19T21:36:21.798781700Z"
    }
   },
   "id": "45372df9a4c8429e"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['chapter', 'summary', 'input_ids', 'attention_mask'],\n    num_rows: 1012\n})"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_val_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:36:21.810979Z",
     "start_time": "2024-04-19T21:36:21.802511400Z"
    }
   },
   "id": "bcc5687c71876ce3"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# encoded_train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:11:28.983198500Z",
     "start_time": "2024-04-19T21:11:28.955537700Z"
    }
   },
   "id": "606630419739dc2b"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:20:32.581972500Z",
     "start_time": "2024-04-19T21:20:32.490408800Z"
    }
   },
   "id": "6409409bf6ac81a3"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:30:22.821308400Z",
     "start_time": "2024-04-19T21:30:22.173232100Z"
    }
   },
   "id": "4b2da725494d317a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "How to Use Rouge\n",
    "At minimum, this metric takes as input a list of predictions and a list of references:\n",
    "\n",
    ">>> rouge = evaluate.load('rouge')\n",
    ">>> predictions = [\"hello there\", \"general kenobi\"]\n",
    ">>> references = [\"hello there\", \"general kenobi\"]\n",
    ">>> results = rouge.compute(predictions=predictions,\n",
    "...                         references=references)\n",
    ">>> print(results)\n",
    "{'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
    "One can also pass a custom tokenizer which is especially useful for non-latin languages.\n",
    "\n",
    ">>> results = rouge.compute(predictions=predictions,\n",
    "...                         references=references,\n",
    "                            tokenizer=lambda x: x.split())\n",
    ">>> print(results)\n",
    "{'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
    "It can also deal with lists of references for each predictions:\n",
    "\n",
    ">>> rouge = evaluate.load('rouge')\n",
    ">>> predictions = [\"hello there\", \"general kenobi\"]\n",
    ">>> references = [[\"hello\", \"there\"], [\"general kenobi\", \"general yoda\"]]\n",
    ">>> results = rouge.compute(predictions=predictions,\n",
    "...                         references=references)\n",
    ">>> print(results)\n",
    "{'rouge1': 0.8333, 'rouge2': 0.5, 'rougeL': 0.8333, 'rougeLsum': 0.8333}```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ef91ae2fe690d73"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\cours\\PA\\venv\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[43], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m trainer \u001B[38;5;241m=\u001B[39m \u001B[43mTrainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoded_train_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoded_val_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrouge\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\cours\\PA\\venv\\Lib\\site-packages\\transformers\\trainer.py:446\u001B[0m, in \u001B[0;36mTrainer.__init__\u001B[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001B[0m\n\u001B[0;32m    444\u001B[0m \u001B[38;5;66;03m# At this stage the model is already loaded\u001B[39;00m\n\u001B[0;32m    445\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_quantized_and_base_model \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_peft_model(model):\n\u001B[1;32m--> 446\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    447\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    448\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    449\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m for more details\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    450\u001B[0m     )\n\u001B[0;32m    451\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m _is_quantized_and_base_model \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _quantization_method_supports_training:\n\u001B[0;32m    452\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    453\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe model you are trying to fine-tune is quantized with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39mhf_quantizer\u001B[38;5;241m.\u001B[39mquantization_config\u001B[38;5;241m.\u001B[39mquant_method\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    454\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m but that quantization method do not support training. Please open an issue on GitHub: https://github.com/huggingface/transformers\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    455\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m to request the support for training support for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39mhf_quantizer\u001B[38;5;241m.\u001B[39mquantization_config\u001B[38;5;241m.\u001B[39mquant_method\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    456\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_val_dataset,\n",
    "    compute_metrics=rouge,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T21:37:11.301100700Z",
     "start_time": "2024-04-19T21:37:11.067523900Z"
    }
   },
   "id": "7586a4126c2f95c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6366767320253bfc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
