{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:21:37.158058200Z",
     "start_time": "2024-04-28T20:21:23.585066Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    use_rslora=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:21:37.175243900Z",
     "start_time": "2024-04-28T20:21:37.159061400Z"
    }
   },
   "id": "a807a9179fb53681"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"pszemraj/booksum-short\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:21:39.691454600Z",
     "start_time": "2024-04-28T20:21:37.166220800Z"
    }
   },
   "id": "7263fc51f1ae225f"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "        # load_in_8bit=True,\n",
    "        load_in_4bit=True,\n",
    "        # llm_int8_enable_fp32_cpu_offload=True,\n",
    "        # llm_int8_has_fp16_weight=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=\"float16\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:21:39.697812800Z",
     "start_time": "2024-04-28T20:21:39.691454600Z"
    }
   },
   "id": "261dd87971875d73"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:21:39.708918Z",
     "start_time": "2024-04-28T20:21:39.697812800Z"
    }
   },
   "id": "89ea41671bac7df1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f245d89d9be47e28641aa5dd3ae0b71"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", quantization_config=quantization_config, device_map=\"auto\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:02.626207100Z",
     "start_time": "2024-04-28T20:21:39.702922200Z"
    }
   },
   "id": "1a28c0ec89c553f3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", model_max_length=128)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:02.805837600Z",
     "start_time": "2024-04-28T20:22:02.626207100Z"
    }
   },
   "id": "23934443aa3ee2a3"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is your favourite condiment?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:02.812324500Z",
     "start_time": "2024-04-28T20:22:02.806837400Z"
    }
   },
   "id": "992cca422d0efe21"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "E:\\cours\\PA\\venv\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:688: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] What is your favourite condiment? [/INST]Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!</s> [INST] Do you have mayonnaise recipes? [/INST] While I don't have the ability to create or prepare recipes myself, I'd be happy to help you make a classic mayonnaise using simple ingredients. Here's a simple Mayonnaise recipe you can try at home:\n",
      "\n",
      "Ingredients:\n",
      "1. 1 cup (240 ml) vegetable oil\n",
      "2. 1 egg yolk\n",
      "3. 1 tablespoon water\n",
      "4. 1 tablespoon distilled white vinegar or lemon juice\n",
      "5. 1 teaspoon Dijon mustard\n",
      "6. 1 teaspoon salt\n",
      "\n",
      "Instructions:\n",
      "1. In a clean and dry bowl, whisk together the egg yolk, water, vinegar or lemon juice, Dijon mustard, and salt.\n",
      "2. Very slowly, drop by drop, start adding the oil to the mixture, while continuously whisking the ingredients together.\n",
      "3. Once half of the oil has been incorporated, you can start adding the oil in a thin, steady stream while continuing to whisk.\n",
      "4. When all the oil has been added, the mayonnaise should be thick and creamy.\n",
      "5. Add more salt, vinegar or lemon juice to taste if desired.\n",
      "6. Cover the bowl with plastic wrap and refrigerate for an hour before using.\n",
      "\n",
      "Remember, it is essential to use a clean bowl and implement the oil drop by drop while whisking constantly to prevent the emulsion from breaking. Enjoy your homemade mayonnaise!</s>\n"
     ]
    }
   ],
   "source": [
    "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "model_inputs = encodeds.to(device)\n",
    "# model.to(device)\n",
    "\n",
    "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:23.699558900Z",
     "start_time": "2024-04-28T20:22:02.811324600Z"
    }
   },
   "id": "b4daafb425acfd93"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"].select_columns(['chapter', 'summary']).select(range(10))\n",
    "val_dataset = dataset[\"validation\"].select_columns(['chapter', 'summary']).select(range(10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:23.707117100Z",
     "start_time": "2024-04-28T20:22:23.694040500Z"
    }
   },
   "id": "b17151a120d20d86"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['chapter', 'summary'],\n",
      "    num_rows: 10\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:23.717288500Z",
     "start_time": "2024-04-28T20:22:23.703741600Z"
    }
   },
   "id": "82ddcf8f14a29e68"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['bid', 'is_aggregate', 'source', 'chapter_path', 'summary_path', 'book_id', 'summary_id', 'content', 'summary', 'chapter', 'chapter_length', 'summary_name', 'summary_url', 'summary_text', 'summary_analysis', 'summary_length', 'analysis_length'],\n",
      "        num_rows: 5912\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['bid', 'is_aggregate', 'source', 'chapter_path', 'summary_path', 'book_id', 'summary_id', 'content', 'summary', 'chapter', 'chapter_length', 'summary_name', 'summary_url', 'summary_text', 'summary_analysis', 'summary_length', 'analysis_length'],\n",
      "        num_rows: 1012\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['bid', 'is_aggregate', 'source', 'chapter_path', 'summary_path', 'book_id', 'summary_id', 'content', 'summary', 'chapter', 'chapter_length', 'summary_name', 'summary_url', 'summary_text', 'summary_analysis', 'summary_length', 'analysis_length'],\n",
      "        num_rows: 988\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:23.717288500Z",
     "start_time": "2024-04-28T20:22:23.710127600Z"
    }
   },
   "id": "67ac210affa99d5e"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def encode(dataset):\n",
    "    return tokenizer(dataset[\"chapter\"], dataset[\"summary\"], truncation=True, padding=\"max_length\", max_length=128)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:23.720294300Z",
     "start_time": "2024-04-28T20:22:23.715277700Z"
    }
   },
   "id": "a21c8d680b03aa8f"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f160c62a3729403c99beacb4b6a1fb19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_train_dataset = train_dataset.map(encode, batched=True)\n",
    "encoded_val_dataset = val_dataset.map(encode, batched=True)\n",
    "\n",
    "# encoded_train_dataset = train_dataset.map(encode)\n",
    "# encoded_val_dataset = val_dataset.map(encode)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:24.213370800Z",
     "start_time": "2024-04-28T20:22:23.721295100Z"
    }
   },
   "id": "21b6dcf401ac90a"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['chapter', 'summary', 'input_ids', 'attention_mask'],\n    num_rows: 10\n})"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:24.219870Z",
     "start_time": "2024-04-28T20:22:24.214371Z"
    }
   },
   "id": "570b7e49609a049"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "128"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_train_dataset['input_ids'][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:24.227127300Z",
     "start_time": "2024-04-28T20:22:24.220871600Z"
    }
   },
   "id": "a567360114da9c78"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_train_dataset['attention_mask'][1][:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:24.229648400Z",
     "start_time": "2024-04-28T20:22:24.224154500Z"
    }
   },
   "id": "bf1357474fb1ad28"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '', '\\n', '', '\"', 'Well', ',', 'go', 'thy', 'way', ':', 'thou', 'sh', 'alt', 'not', 'from', 'this', 'gro', 've', '\\n', '', 'T', 'ill', 'I', 'tor', 'ment', 'the', 'e', 'for', 'this', 'injury', '.\"', '\\n', '\\n', '', '_', 'M', 'id', 'sum', 'mer', 'Night', \"'\", 's', 'Dream', '._', '\\n', '\\n', '\\n', 'The', 'words', 'were', 'still', 'in', 'the', 'mouth', 'of', 'the', 'sc', 'out', ',', 'when', 'the', 'leader', 'of', '<s>', '{\"', 'name', '\":', '\"', 'Ch', 'apter', '', '4', '\",', '\"', 'url', '\":', '\"', 'https', '://', 'web', '.', 'archive', '.', 'org', '/', 'web', '/', '2', '0', '2', '0', '1', '1', '0', '1', '0', '5', '3', '2', '0', '5', '/', 'https', '://', 'www', '.', 'cl', 'iffs', 'notes', '.', 'com', '/', 'liter', 'ature', '/', 'l', '/', 'the', '-', 'last', '-', 'of', '-', 'the', '-', 'm', 'oh']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(encoded_train_dataset['input_ids'][1]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:24.237068600Z",
     "start_time": "2024-04-28T20:22:24.229648400Z"
    }
   },
   "id": "9b89e5448196482f"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[1,\n 28705,\n 13,\n 28705,\n 345,\n 11273,\n 1167,\n 5080,\n 654,\n 480,\n 1334,\n 304,\n 261,\n 2636,\n 28725,\n 13,\n 2287,\n 11439,\n 298,\n 272,\n 1170,\n 321,\n 813,\n 24582,\n 4699,\n 286,\n 28745,\n 13,\n 28705,\n 415,\n 8970,\n 1174,\n 302,\n 15507,\n 6774,\n 13,\n 2287,\n 415,\n 6138,\n 304,\n 3585,\n 1503,\n 4768,\n 28745,\n 13,\n 28705,\n 1015,\n 5063,\n 1114,\n 28713,\n 26108,\n 28725,\n 304,\n 8191,\n 28718,\n 7835,\n 4226,\n 28725,\n 13,\n 2287,\n 1015,\n 285,\n 696,\n 1606,\n 1,\n 9830,\n 861,\n 1264,\n 345,\n 1209,\n 2902,\n 28705,\n 28770,\n 548,\n 345,\n 2179,\n 1264,\n 345,\n 3887,\n 1508,\n 4311,\n 28723,\n 23682,\n 28723,\n 1909,\n 28748,\n 4311,\n 28748,\n 28750,\n 28734,\n 28750,\n 28734,\n 28740,\n 28740,\n 28734,\n 28740,\n 28734,\n 28782,\n 28770,\n 28750,\n 28734,\n 28782,\n 28748,\n 3887,\n 1508,\n 2849,\n 28723,\n 512,\n 17820,\n 18787,\n 28723,\n 675,\n 28748,\n 24477,\n 1373,\n 28748,\n 28714,\n 28748,\n 1237,\n 28733,\n 4081,\n 28733,\n 1009,\n 28733,\n 1237,\n 28733,\n 28719,\n 1371]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_dataset['input_ids'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:24.292495300Z",
     "start_time": "2024-04-28T20:22:24.235065700Z"
    }
   },
   "id": "dd0cfef91d4969f4"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_train_dataset['input_ids'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:24.292495300Z",
     "start_time": "2024-04-28T20:22:24.242598Z"
    }
   },
   "id": "45372df9a4c8429e"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['chapter', 'summary', 'input_ids', 'attention_mask'],\n    num_rows: 10\n})"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_val_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:24.293636100Z",
     "start_time": "2024-04-28T20:22:24.247698700Z"
    }
   },
   "id": "bcc5687c71876ce3"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['chapter', 'summary', 'input_ids', 'attention_mask'],\n    num_rows: 10\n})"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:24.293636100Z",
     "start_time": "2024-04-28T20:22:24.252215300Z"
    }
   },
   "id": "da0f652ddcdf131d"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# encoded_train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:24.293636100Z",
     "start_time": "2024-04-28T20:22:24.256046200Z"
    }
   },
   "id": "606630419739dc2b"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
    "                                  per_device_train_batch_size=1,\n",
    "                                  per_device_eval_batch_size=1,\n",
    "                                  num_train_epochs=5,\n",
    "                                  learning_rate=0.001\n",
    "                                  )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:24.375291600Z",
     "start_time": "2024-04-28T20:22:24.260403500Z"
    }
   },
   "id": "6409409bf6ac81a3"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:25.686427700Z",
     "start_time": "2024-04-28T20:22:24.315872Z"
    }
   },
   "id": "4b2da725494d317a"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "model.add_adapter(peft_config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:26.088613300Z",
     "start_time": "2024-04-28T20:22:25.687424800Z"
    }
   },
   "id": "705596b4ab2ec935"
  },
  {
   "cell_type": "markdown",
   "source": [
    "How to Use Rouge\n",
    "At minimum, this metric takes as input a list of predictions and a list of references:\n",
    "\n",
    ">>> rouge = evaluate.load('rouge')\n",
    ">>> predictions = [\"hello there\", \"general kenobi\"]\n",
    ">>> references = [\"hello there\", \"general kenobi\"]\n",
    ">>> results = rouge.compute(predictions=predictions,\n",
    "...                         references=references)\n",
    ">>> print(results)\n",
    "{'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
    "One can also pass a custom tokenizer which is especially useful for non-latin languages.\n",
    "\n",
    ">>> results = rouge.compute(predictions=predictions,\n",
    "...                         references=references,\n",
    "                            tokenizer=lambda x: x.split())\n",
    ">>> print(results)\n",
    "{'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
    "It can also deal with lists of references for each predictions:\n",
    "\n",
    ">>> rouge = evaluate.load('rouge')\n",
    ">>> predictions = [\"hello there\", \"general kenobi\"]\n",
    ">>> references = [[\"hello\", \"there\"], [\"general kenobi\", \"general yoda\"]]\n",
    ">>> results = rouge.compute(predictions=predictions,\n",
    "...                         references=references)\n",
    ">>> print(results)\n",
    "{'rouge1': 0.8333, 'rouge2': 0.5, 'rougeL': 0.8333, 'rougeLsum': 0.8333}```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ef91ae2fe690d73"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\cours\\PA\\venv\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_val_dataset,\n",
    "    compute_metrics=rouge\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:26.108167900Z",
     "start_time": "2024-04-28T20:22:26.088613300Z"
    }
   },
   "id": "7586a4126c2f95c7"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\cours\\PA\\venv\\Lib\\site-packages\\transformers\\trainer.py:1780\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1778\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   1779\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1780\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1781\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1782\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1783\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1784\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1785\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\cours\\PA\\venv\\Lib\\site-packages\\transformers\\trainer.py:2118\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_begin(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[0;32m   2117\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39maccumulate(model):\n\u001B[1;32m-> 2118\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   2121\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[0;32m   2122\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[0;32m   2123\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[0;32m   2124\u001B[0m ):\n\u001B[0;32m   2125\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[0;32m   2126\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[1;32mE:\\cours\\PA\\venv\\Lib\\site-packages\\transformers\\trainer.py:3036\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[1;34m(self, model, inputs)\u001B[0m\n\u001B[0;32m   3033\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m   3035\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[1;32m-> 3036\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3038\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mn_gpu \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3039\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mmean()  \u001B[38;5;66;03m# mean() to average on multi-gpu parallel training\u001B[39;00m\n",
      "File \u001B[1;32mE:\\cours\\PA\\venv\\Lib\\site-packages\\transformers\\trainer.py:3077\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[1;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[0;32m   3075\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3076\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(outputs, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m outputs:\n\u001B[1;32m-> 3077\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   3078\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe model did not return a loss from the inputs, only the following keys: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3079\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(outputs\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. For reference, the inputs it received are \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(inputs\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3080\u001B[0m         )\n\u001B[0;32m   3081\u001B[0m     \u001B[38;5;66;03m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001B[39;00m\n\u001B[0;32m   3082\u001B[0m     loss \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(outputs, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m outputs[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mValueError\u001B[0m: The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:27.502204700Z",
     "start_time": "2024-04-28T20:22:26.102640600Z"
    }
   },
   "id": "6366767320253bfc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:27.503202300Z",
     "start_time": "2024-04-28T20:22:27.503202300Z"
    }
   },
   "id": "4bf017f90b6cb5eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(encoded_train_dataset['attention_mask'][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T20:22:27.504421800Z",
     "start_time": "2024-04-28T20:22:27.504421800Z"
    }
   },
   "id": "943bbffbc30f0e5e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(encoded_train_dataset['attention_mask'][78]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T20:22:27.505428900Z"
    }
   },
   "id": "29712cac9bb0dcba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "80221280ffa61a47"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[72], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(encoded_train_dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m])):\n\u001B[1;32m----> 2\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[43mencoded_train_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput_ids\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m[i]) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m11593\u001B[39m:\n\u001B[0;32m      3\u001B[0m         \u001B[38;5;28mprint\u001B[39m(i)\n",
      "File \u001B[1;32mE:\\cours\\PA\\venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:2810\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2808\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[0;32m   2809\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[1;32m-> 2810\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\cours\\PA\\venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:2795\u001B[0m, in \u001B[0;36mDataset._getitem\u001B[1;34m(self, key, **kwargs)\u001B[0m\n\u001B[0;32m   2793\u001B[0m formatter \u001B[38;5;241m=\u001B[39m get_formatter(format_type, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info\u001B[38;5;241m.\u001B[39mfeatures, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mformat_kwargs)\n\u001B[0;32m   2794\u001B[0m pa_subtable \u001B[38;5;241m=\u001B[39m query_table(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data, key, indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indices)\n\u001B[1;32m-> 2795\u001B[0m formatted_output \u001B[38;5;241m=\u001B[39m \u001B[43mformat_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpa_subtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformatter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformatter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformat_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformat_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_all_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_all_columns\u001B[49m\n\u001B[0;32m   2797\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2798\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "File \u001B[1;32mE:\\cours\\PA\\venv\\Lib\\site-packages\\datasets\\formatting\\formatting.py:629\u001B[0m, in \u001B[0;36mformat_table\u001B[1;34m(table, key, formatter, format_columns, output_all_columns)\u001B[0m\n\u001B[0;32m    627\u001B[0m python_formatter \u001B[38;5;241m=\u001B[39m PythonFormatter(features\u001B[38;5;241m=\u001B[39mformatter\u001B[38;5;241m.\u001B[39mfeatures)\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m format_columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 629\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mformatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumn\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m format_columns:\n",
      "File \u001B[1;32mE:\\cours\\PA\\venv\\Lib\\site-packages\\datasets\\formatting\\formatting.py:398\u001B[0m, in \u001B[0;36mFormatter.__call__\u001B[1;34m(self, pa_table, query_type)\u001B[0m\n\u001B[0;32m    396\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_row(pa_table)\n\u001B[0;32m    397\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumn\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 398\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_column\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    400\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_batch(pa_table)\n",
      "File \u001B[1;32mE:\\cours\\PA\\venv\\Lib\\site-packages\\datasets\\formatting\\formatting.py:442\u001B[0m, in \u001B[0;36mPythonFormatter.format_column\u001B[1;34m(self, pa_table)\u001B[0m\n\u001B[0;32m    440\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mformat_column\u001B[39m(\u001B[38;5;28mself\u001B[39m, pa_table: pa\u001B[38;5;241m.\u001B[39mTable) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m:\n\u001B[0;32m    441\u001B[0m     column \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpython_arrow_extractor()\u001B[38;5;241m.\u001B[39mextract_column(pa_table)\n\u001B[1;32m--> 442\u001B[0m     column \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpython_features_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode_column\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpa_table\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumn_names\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    443\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m column\n",
      "File \u001B[1;32mE:\\cours\\PA\\venv\\Lib\\site-packages\\datasets\\formatting\\formatting.py:217\u001B[0m, in \u001B[0;36mPythonFeaturesDecoder.decode_column\u001B[1;34m(self, column, column_name)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode_row\u001B[39m(\u001B[38;5;28mself\u001B[39m, row: \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures\u001B[38;5;241m.\u001B[39mdecode_example(row) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures \u001B[38;5;28;01melse\u001B[39;00m row\n\u001B[1;32m--> 217\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode_column\u001B[39m(\u001B[38;5;28mself\u001B[39m, column: \u001B[38;5;28mlist\u001B[39m, column_name: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m:\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures\u001B[38;5;241m.\u001B[39mdecode_column(column, column_name) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures \u001B[38;5;28;01melse\u001B[39;00m column\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode_batch\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch: \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(encoded_train_dataset['input_ids'])):\n",
    "    if len(encoded_train_dataset['input_ids'][i]) == 11593:\n",
    "        print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T18:25:18.479775400Z",
     "start_time": "2024-04-28T18:18:42.617101200Z"
    }
   },
   "id": "83dd58e6b4acf72c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b2616ae4e0788344"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
